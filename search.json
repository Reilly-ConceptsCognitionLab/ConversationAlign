[{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Jamie Reilly. Author, maintainer. Virginia Ulichney. Author. Ben Sacks. Author. Anna Duncan. Contributor. Sarah Weinstein. Contributor. Tania Giovannetti. Contributor. Chelsea Helion. Contributor.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Reilly J, Ulichney V, Sacks B (2023). ConversationAlign: ConversationAlign. https://reilly-conceptscognitionlab.github.io/ConversationAlign, https://reilly-conceptscognitionlab.github.io/ConversationAlign/.","code":"@Manual{,   title = {ConversationAlign: ConversationAlign},   author = {Jamie Reilly and Virginia Ulichney and Ben Sacks},   year = {2023},   note = {https://reilly-conceptscognitionlab.github.io/ConversationAlign, https://reilly-conceptscognitionlab.github.io/ConversationAlign/}, }"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"conversationalign","dir":"","previous_headings":"","what":"ConversationAlign","title":"ConversationAlign","text":"October 2023: ConversationAlign works still development!  Proceed caution. Cross-reference processing stage original transcripts.  Email jamie_reilly@temple.edu jumping . help !","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"ConversationAlign","text":"ConversationAlign analyzes alignment interlocutors (conversation partners) engaged two-person conversations. ConversationAlign works language transcripts. can handle text files (.txt) comma separated value (.csv) spreadsheet style files. ConversationAlign transforms raw language data simultaneous time series objects spanning 30 possible dimensions via embedded lookup database. ’s schematic guts program… overview ConversationAlign","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"before-starting-prep-your-data","dir":"","previous_headings":"","what":"Before starting: Prep your data","title":"ConversationAlign","text":"ConversationAlign can handle home brew preferred format. However, transcripts must following header columns bare minimum:  1) Participant identifier (named Interlocutor’, ‘Speaker’, ‘Participant’)  2) Text (named ‘Text’, ‘Utterance’, ‘Turn’) order columns matter. data transcripts (e.g., metadata, timestamps, grouping variables) retained. ’s example transcript work. Don’t worry stripping punctuation. .  Considerations prepping language transcripts ConversationAlign: Save conversation transcript separate file (e.g., MaryJoe_FirstDateTalk.txt) careful/deliberate filenaming convention. filename conversation become event ID dataframe Move language transcripts analyzed one folder (e.g., “my_transcripts”) directory running R script. metadata (e.g., age, timestamps, grouping variables), can either append original transcript merge metdata separate file. useful option many individual difference demographic details.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"ConversationAlign","text":"Install development version ConversationAlign GitHub entering following console script:","code":"install.packages(\"devtools\") devtools::install_github(\"Reilly-ConceptsCognitionLab/ConversationAlign\")"},{"path":[]},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"read_dyads","dir":"","previous_headings":"","what":"read_dyads()","title":"ConversationAlign","text":"function read files concatenate single dataframe, appending document IDs. can call dataframe whatever like. ‘read_dyads’ default reading csv txt files folder called my_transcripts. Just remember finished processing set transcripts, make sure move folder. can think ‘my_transcripts’ staging area loading data ConversationAlign.","code":"MyRawLangSamples <- read_dyads() #if you want to specify a different folder, supply your own path MyRawLangSamples <- read_dyads(\"/my_custompath\")"},{"path":[]},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"clean_dyads","dir":"","previous_headings":"","what":"clean_dyads()","title":"ConversationAlign","text":"‘clean_dyads’ uses numerous regex clean format data just read R previous step. Although many cleaning steps, big ones: 1) lowercase 2) omit stopwords 3) replace contractions (e.g., ‘’re’ ‘’) 4) tick marks apostrophes 5) hypens spaces 6) omits numerals 7) omits/squishes extraneous white space 8) lemmatization ConversationAlign calls textstem package dependency lemmatize language transcript. converts morphologiocal derivatives root forms. default lemmatize=T. Sometimes want retain language output native form. case, change argument clean_dyads lemmatize=F. ‘clean_dyads’ outputs word count metrics pre/post cleaning dyad interlocutor. can useful interested whether one person just doesn’t produce many words produces great deal empty utterances.","code":"MyCleanLangSamples <- clean_dyads(MyRawLangSamples) #default is lemmatize=TRUE #If you do NOT want your language sample lemmatized, change the lemmatize argument to F or FALSE MyCleanLangSamples <- clean_dyads(MyRawLangSamples, lemmatize=FALSE)"},{"path":[]},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"align_dyads","dir":"","previous_headings":"","what":"align_dyads()","title":"ConversationAlign","text":"lot magic happens. align_dyads take cleaned dataframe created last step yoke values every word indexing lookup database. “align” step yokes data word cleaned transcript text structures dataframe speaker (“Participant_ID”), exchange (“exchangecount”), turn (“turncount”) across dyad (“event_id”). prompted select one variables (three) yoke data used later steps compute alignment indices. shown menu wherein can select three variables yoked text. Following menu steps, enter number variable like space separating values (e.g., “10 14 19”). choices: anger, anxiety, boredom, closeness, confusion, dominance, doubt, empathy, encouragement, excitement, guilt, happiness, hope, hostility, politeness, sadness, stress, surprise, trust, valence, age acquisition, word length (letters), morphemes per turn, prevalence (many people know word), number word senses (polysemy), word frequency (lg10), arousal, concreteness, semantic diversity, semantic neighbors. https://reilly-lab.github.io/ConversationAlign_VariableLookupKey.pdf select variables like yoked text, asked whether metadata like yoked data can supply filepath csv file containing metadata merged aligned data juncture, click “Enter” skip step. Run align_dyads cleaned dyads object created using clean_dyads function.","code":"MyAlignedDyads <- align_dyads(MyCleanLangSamples)"},{"path":[]},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"summarize_dyads","dir":"","previous_headings":"","what":"summarize_dyads()","title":"ConversationAlign","text":"Lastly, using object produced prior align step, can obtain metrics linguistic alignment interlocutors variables yoked text “align”. step, gain metrics (1) means variable per interlocutor per turn (beginning prefix “mean_”), (2) area curve (beginning prefix “auc_”) per variable per dyad per exchange, (3) Spearman’s correlation coefficient (beginning prefix (“S_rho_”) per variable per dyad per exchange. means variable usage calculated per interlocutor per turn dimension within dyad, calculated using “mean” function “base” package R (R Core Team, 2023). AUC denotes area beneath curve absolute difference speakers’ expression variable exchanges interaction across exchanges within dyad, calculated using “AUC” function “DescTools” package R (Signorell et al., https://andrisignorell.github.io/DescTools/). Spearman’s correlation coefficient provides metric overall association two interlocutors’ scores variable language exchanges, calculated using “cor.test(method =”spearman”)” function “stats” package R (R Core Team, 2023). means within dyads, interlocutor independent means variable, interlocutors AUC Spearman’s correlation coefficient one another.","code":"MySummarizedDyads <- summarize_dyads(MyAlignedDyads)"},{"path":[]},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"things-you-must-be-careful-about","dir":"","previous_headings":"","what":"Things you must be careful about","title":"ConversationAlign","text":"analysis language comes assumptions potential bias. example, instances researcher might care morphemes grammatical elements ‘’, ‘’, ‘’, etc.. default ConversationAlign omit stopwords average across open class words (e.g., nouns, verbs) turn interlocutor. specific cases can go wrong. ’s need consider: Stopwords: package omits stopwords. See stopword list like inspect list. included greetings, idioms, filler words, numerals, pronouns omissions list. Lemmatization: package lemmatize language transcripts default. Lemmatization transforms inflected forms (e.g., standing, stands) root dictionary entry (e.g., stand). helps yoking offline values (e.g., happiness, concreteness) word also entails NLP folks refer ‘term aggregation’. However, sometimes might want lemmatize. can easily change option using argument, “lemmatize=FALSE,” clean_dyads function . Sample Size Issue 1– exchange count: program derives correlations AUC dyad metrics alignment. 40 exchanges (80 turns) conversation partners, R value computed 40 data points. conversations less 30 turns, trust R values ConversationAlign outputs. Sample Size Issue 2 : matching lookup database: ConversationAlign works yoking values lookup database word language transcript. variables lots values characterizing many English words. variables (e.g., age acquisition) cover 30k words. word transcript ‘match’ lookup datase, ConversationAlign return NA go average words interlocutor turn. can dangerous many missing values. Beware! Compositionality : ConversationAlign caveman complexity. matches value word word island. Phenomena like polysemy (e.g., bank) modulation one word intensifier (e.g., terrible) handled. problem many affective measures lexical variables like word length. Resampling AUC : summarize_dyads output AUC values quantifying distance interlocutors dimension specify. AUC vary depending length dyad. Therefore, often necessary resample (downsample) dyads equivalent length. get wonky uninterpretable short exchanges.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"get-in-touch","dir":"","previous_headings":"","what":"Get in touch!","title":"ConversationAlign","text":"Contact jamie_reilly@temple.edu feedback assistance.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/align_dyads.html","id":null,"dir":"Reference","previous_headings":"","what":"align_dyads — align_dyads","title":"align_dyads — align_dyads","text":"Yokes user-specified semantic, affective, phonological values word cleaned language transcript. Prepares dataframe aligned exchange turn across Participant_IDs.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/align_dyads.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"align_dyads — align_dyads","text":"","code":"align_dyads(clean_ts_df)"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/align_dyads.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"align_dyads — align_dyads","text":"clean_ts_df cleaned formatted dataframe ported clean_dyads() step","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/clean_dyads.html","id":null,"dir":"Reference","previous_headings":"","what":"clean_dyads — clean_dyads","title":"clean_dyads — clean_dyads","text":"Cleans Formats raw language transcripts, removing stopwords formatting dataframe alignment steps","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/clean_dyads.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"clean_dyads — clean_dyads","text":"","code":"clean_dyads(read_ts_df, lemmatize = TRUE)"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/clean_dyads.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"clean_dyads — clean_dyads","text":"read_ts_df formatted dataframe ported read_dyads() step","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/hello.html","id":null,"dir":"Reference","previous_headings":"","what":"Hello, World! — hello","title":"Hello, World! — hello","text":"Prints 'Hello, world!'.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/hello.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hello, World! — hello","text":"","code":"hello()"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/hello.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Hello, World! — hello","text":"","code":"hello() #> Error in hello(): could not find function \"hello\""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/read_dyads.html","id":null,"dir":"Reference","previous_headings":"","what":"read_dyads — read_dyads","title":"read_dyads — read_dyads","text":"Reads pre-formatted conversation transcripts txt csv user's machine; user supplies directory path (e.g., \"my_transcripts\") local folder argument function call","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/read_dyads.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"read_dyads — read_dyads","text":"","code":"read_dyads(folder_name = \"my_transcripts\")"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/read_dyads.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"read_dyads — read_dyads","text":"folder_name user can specify folder name directory language transcripts read , default '-transcripts' root","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/summarize_dyads.html","id":null,"dir":"Reference","previous_headings":"","what":"summarize_dyads — summarize_dyads","title":"summarize_dyads — summarize_dyads","text":"appends AUC Spearman Rank Correlation indices dyad (event_id) using resampling algoirthm defaults minimum number exchanges across documents entered","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/summarize_dyads.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"summarize_dyads — summarize_dyads","text":"","code":"summarize_dyads(aligned_ts_df, resample_yes_or_no = TRUE, resample_n = \"min\")"}]
