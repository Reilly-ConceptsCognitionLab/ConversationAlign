[{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Jamie Reilly. Author, maintainer. Virginia Ulichney. Author. Ben Sacks. Author. Sarah Weinstein. Contributor. Chelsea Helion. Contributor. Gus Cooney. Contributor.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Reilly J, Ulichney V, Sacks B (2025). ConversationAlign: ConversationAlign. R package version 0.2.0, https://github.com/Reilly-ConceptsCognitionLab/ConversationAlign/blob/main/CHANGELOG.md.","code":"@Manual{,   title = {ConversationAlign: ConversationAlign},   author = {Jamie Reilly and Virginia Ulichney and Ben Sacks},   year = {2025},   note = {R package version 0.2.0},   url = {https://github.com/Reilly-ConceptsCognitionLab/ConversationAlign/blob/main/CHANGELOG.md}, }"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"conversationalign","dir":"","previous_headings":"","what":"ConversationAlign","title":"ConversationAlign","text":"Open-source software computing main effects indices alignment across coversation partners dyadic conversation transcripts. ConversationAlign analyzes alignment interlocutors (conversation partners) engaged two-person conversations. ConversationAlign works language transcripts. can handle text files (.txt) comma separated value (.csv) spreadsheet style files. ConversationAlign transforms raw language data simultaneous time series objects spanning 30 possible dimensions via embedded lookup database.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"ConversationAlign","text":"’s schematic ConversationAlign processes conversation transcript. overview ConversationAlign","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"ConversationAlign","text":"Install development version ConversationAlign GitHub using devtools package.","code":"# Check if devtools is installed, if not install it if (!require(\"devtools\", quietly = TRUE)) {   install.packages(\"devtools\") }  # Load devtools library(devtools)  # Check if ConversationAlign is installed, if not install from GitHub if (!require(\"ConversationAlign\", quietly = TRUE)) {   devtools::install_github(\"Reilly-ConceptsCognitionLab/ConversationAlign\") }  # Load SemanticDistance library(ConversationAlign)"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"an-introduction-to-conversationalign","dir":"","previous_headings":"","what":"An Introduction to ConversationAlign","title":"ConversationAlign","text":"ConversationAlign tool computing main effects alignment dynamics 2-person conversation transcripts. present, ConversationAlign capable analyzing synchrony across 30 different affective, lexical, semantic dimensions. Email Jamie Reilly suggest . demo follow, analyze real conversation transcript included package. transcript reflects classic interview American radio host, Terry Gross, comedian, Marc Maron, first broadcast National Public Radio (2013). first 20 lines. Conversation ideally cooperative endeavor parties modify form content production align . phenomenon known alignment. People align across many, many dimensions including word choices emotional coloring. ConversationAlign can measure differences (e.g., older people use concrete words younger people?) synchrony (e.g., people similar educational attainment show higher rates alignment?) across many factors. planning analysis, recommend choose factors directional hypothesis mind.","code":"knitr::kable(head(MaronGross_2013, 10),               format = \"pipe\",               col.names = c(\"**speaker**\", \"**text**\"))"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"preparing-your-data","dir":"","previous_headings":"","what":"Preparing Your Data","title":"ConversationAlign","text":"ConversationAlign works dyadic language transcripts (.e., 2-person dialogues). raw transcript MUST contain least two columns, interlocutor (.e., speaker) text. order columns matter. Metadata conserved (e.g., timestamps, grouping variables, physio values). Don’t worry stripping punctuation splitting words across rows. long corresponding text within turn marked talkerID, ConversationAlign split text append rowwise labels. Label talker/interlocutor column ‘Interlocutor’, ‘Speaker’, ‘Participant’. Label text column ‘Text’, ‘Utterance’, ‘Turn’. Save conversation transcript somwehere computer separate file (CSV txt work best). careful/deliberate filenaming convention. filename conversation become event ID (document_id). might need processing large corpora. Stage individual conversation transcripts analyzed one folder (e.g., “my_transcripts”). folder ideally nested directory running R script .","code":""},{"path":[]},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"read_dyads","dir":"","previous_headings":"","what":"read_dyads()","title":"ConversationAlign","text":"read_dyads() import conversation transcripts machine’s target folder R. function also concatenate individual transcripts single dataframe. transcript’s filename become Event_ID dataframe. want skip read step format dataframe manually R, need three columns named exactly: 1. Event_ID column header unique marker conversation transcript (variable factor)  2. Paricipant_ID column header delineating producing text given line (variable factor)  3. RawText column header containing raw text (punctuation, unsplit, uncleaned, etc,) Name concatenated dataframe anything like (e.g., MyKidConversations). read_dyads() defaults scanning folder called my_transcripts within directory running scripts . read_dyads() import *.csv, *.txt, Otter *.ai files exist within folder. can also dump transcripts folder labelled however like specifing custom path. import conversation transcript representing 2013 NPR interview (USA) Marc Maron Terry Gross, titled Marc Maron: Life Fueled ‘Panic Dread’. Arguments read_dyads include:  1. folder_name: default ‘my_transcripts’, change path folder name","code":"#Example of custom path #MyConvo <- read_dyads(folder_name = 'mycomputer/my_lang_transcripts')"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"read_1file","dir":"","previous_headings":"","what":"read_1file()","title":"ConversationAlign","text":"Preps one transcript already R environment ConversationAlign. use read_1file() prep Marc Maron Terry Gross transcript. Look column headers changed object name (MaronGross_2013) now Event_ID (document identifier), Arguments read_1file include:  1. my_dat: object already R environment containing text speaker information.","code":"Maron_Prepped <- read_1file(MaronGross_2013)  #print first ten rows of header knitr::kable(head(Maron_Prepped, 10), format = \"pipe\")"},{"path":[]},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"clean_dyads","dir":"","previous_headings":"","what":"clean_dyads()","title":"ConversationAlign","text":"clean_dyads() uses numerous regex clean format data just read R previous step. ConversationAlign applies ordered sequence cleaning steps beginning transforming raw text lowercase. package eventually splits text one-word-per row format number transformations, including: replace contractions (e.g., ‘’re’ ‘’), gsub tick marks apostrophes, gsub hypens spaces, omit numerals, omit non-alphabetic characters, squish extraneous white space. two additional arguments need careful (.e.,lemmatization stopword removal). Let’s briefly review options. Stopwords: Many NLP computer science researchers consider stopwords (e.g., , , , ) semantically empty indices. view contrasts linguists people know language view closed class words integral building meaning. Nevertheless, decision omit stopwords merit. Words ‘’, ‘’, ‘’ overwhelming lexical frequency tend dominate document term matrix. us interested open-class words (e.g., nouns, adjectives, verbs). algorithms ConversationAlign treat language continuous bag--words, stopword removal often essential. careful strategy use remove stopwords. procedure typically involves matching lookup databases composed fixed lists stopwords. lists minimalist highly conservative (e.g., omitting function words). stopword lists (e.g., MIT) quite liberal include substantial numbers open class words might want remove. ConversationAlign includes several options stopword omission, including:  1) None - leave text alone!  2) SMART (english) - provenance original source CLICK . inspect actual stopwords CLICK  3) MIT_Stops - MedialLab. inspect actual stopword list CLICK  4) Temple_Stopwords25 - lab. carefully constructed stopword list tagging POS MIT list omitting open-class words. also included idioms greetings (multiword utterances). ConversationAlign’s default argument omitting stopwords apply Temple_Stopwords25 list. recommend familiarizing characteristics list clicking read construction clicking inspect list . Lemmatization: ConversationAlign calls textstem package dependency lemmatize language transcript. converts morphologiocal derivatives root forms. default lemmatize=T. Sometimes want retain language output native form. case, change argument clean_dyads lemmatize=F. clean_dyads() outputs word count metrics pre/post cleaning dyad interlocutor. can useful interested whether one person just doesn’t produce many words produces great deal empty utterances. Arguments clean_dyads include:  1) read_ts_df = name dataframe created read_dyads()  2) which_stopwords = quoted argument specifying stopword list, options include none, MIT_stops, SMART, CA_OriginalStops, Temple_Stopwords25. Default Temple_Stopwords25. CA_OriginalStops stopword list originally bundled ConversationAlign early development.  3) lemmatize = lemmatize strings converting entry dictionary form, default TRUE","code":"#defaults to function call are 'Temple_Stopwords25' and lemmatize=TRUE Maron_Cleaned <- clean_dyads(read_ts_df=Maron_Prepped, which_stoplist = \"Temple_Stopwords25\", lemmatize=TRUE)  knitr::kable(head(Maron_Cleaned, 15), format = \"pipe\")"},{"path":[]},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"align_dyads","dir":"","previous_headings":"","what":"align_dyads()","title":"ConversationAlign","text":"magic happens. align_dyads() take cleaned dataframe created last step yoke values every word indexing lookup database. align_dyads() step yokes data word cleaned transcript text structures dataframe speaker (“Participant_ID”), exchange (“exchangecount”), turn (“turncount”) across dyad (“event_id”). prompted select one variables (three) yoke data used later steps compute alignment indices. shown menu wherein can select three variables yoked text. Following menu steps, enter number variable like space separating values (e.g., “10 14 19”). choices dimensions align :  anger, anxiety, boredom, closeness, confusion, dominance, doubt, empathy, encouragement, excitement, guilt, happiness, hope, hostility, politeness, sadness, stress, surprise, trust, valence, age acquisition, word length (letters), morphemes per turn, prevalence (many people know word), number word senses (polysemy), word frequency (lg10), arousal, concreteness, semantic diversity, semantic neighbors. Run align_dyads() cleaned dyads object created using clean_dyads() function.","code":"MyAlignedDyads <- align_dyads(MyCleanLangSamples)"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"summarize-transcripts","dir":"","previous_headings":"","what":"Summarize transcripts","title":"ConversationAlign","text":"last step consists three methods, computes seperate index alignment.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"summarize_dyads_auc","dir":"","previous_headings":"","what":"summarize_dyads_auc()","title":"ConversationAlign","text":"returns difference time series AUC (dAUC) every variable interest specified. example, summarize_dyads_auc append dAUC values hostility (’s ’re interested ).","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"summarize_dyads_covar","dir":"","previous_headings":"","what":"summarize_dyads_covar()","title":"ConversationAlign","text":"returns spearman correlation coefficient range lagged Pearson correlation coefficients variable interest. vector Lags/leads Pearson correlations supplied parameter.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"summarize_dyads_slope","dir":"","previous_headings":"","what":"summarize_dyads_slope()","title":"ConversationAlign","text":"return intercept slope simple linear regression interlocutor difference time series variable interest. provides measure change time, providing information aligns .","code":"MyFinalDataframe_AUC <- summarize_dyads_auc(MyAlignedDyads, resample = T) #resample=T computes AUC by homogenizing the length of all dyads to the shortest tramscript (number of turns)   MyFinalDataframe_Covar <- summarize_dyads_covar(MyAlignedDyads, lags = c(-2, -1, 1, 2)) # lags are supplied as a vector, defaulting to a range of [-3, 3]  MyFinalDataframe_Slope <- summarize_dyads_slope(MyAlignedDyads, resample = F) # for auc and slope, when resample=F, it becomes much more difficult to compare metrics between conversations of different lengths."},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"caveat-emptor","dir":"","previous_headings":"","what":"Caveat emptor","title":"ConversationAlign","text":"analysis language comes assumptions potential bias. example, instances researcher might care morphemes grammatical elements ‘’, ‘’, ‘’, etc.. default ConversationAlign omit stopwords average across open class words (e.g., nouns, verbs) turn interlocutor. specific cases can go wrong. things consider: Stopwords : ConversationAlign omits stopwords default applying customized stopword list, Temple_Stopwords25. CLICK inspect list. stopword list includes greetings, idioms, filler words, numerals, pronouns. Lemmatization : package lemmatize language transcripts default. Lemmatization transforms inflected forms (e.g., standing, stands) root dictionary entry (e.g., stand). helps yoking offline values (e.g., happiness, concreteness) word also entails NLP folks refer ‘term aggregation’. However, sometimes might want lemmatize. can easily change option using argument, “lemmatize=FALSE,” clean_dyads function . Sample Size Issue 1: exchange count: program derives correlations AUC dyad metrics alignment. 40 exchanges (80 turns) conversation partners, R value computed 40 data points. conversations less 30 turns, trust R values ConversationAlign outputs. Sample Size Issue 2 : matching lookup database: ConversationAlign works yoking values lookup database word language transcript. variables lots values characterizing many English words. variables (e.g., age acquisition) cover 30k words. word transcript ‘match’ lookup datase, ConversationAlign return NA go average words interlocutor turn. can dangerous many missing values. Beware! Compositionality : ConversationAlign caveman complexity. matches value word word island. Phenomena like polysemy (e.g., bank) modulation one word intensifier (e.g., terrible) handled. problem many affective measures lexical variables like word length. Resampling AUC : summarize_dyads output AUC values quantifying distance interlocutors dimension specify. AUC vary depending length dyad. Therefore, often necessary resample (downsample) dyads equivalent length. get wonky uninterpretable short exchanges.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"background","dir":"","previous_headings":"","what":"Background","title":"ConversationAlign","text":"documents describing derived stopword list lookup databases. Preprint  PsyArXiv preprint describing method(s) greater detail referenced : Sacks, B., Ulichney, V., Duncan, ., Helion, C., Weinstein, S., Giovannetti, T., … Reilly, J. (2025, March 12). ConversationAlign: Open-Source Software Analyzing Patterns Lexical Use Alignment Conversation Transcripts. Click read preprint. recently invited revision Behavior Rsearch Methods. update /eventually accepted ! Methods creating internal lookup database  ConversationAlign contains large, internal lexical lookup_database. Click see created merging offline psycholinguistic databases one. Variable Key ConversationAlign  ConversationAlign currently allows users compute alignment dynamics across 30 different lexical, affective, semantic dimensions.Click link variable key.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"get-in-touch","dir":"","previous_headings":"","what":"Get in touch!","title":"ConversationAlign","text":"Contact jamie_reilly@temple.edu feedback assistance.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"references","dir":"","previous_headings":"","what":"References","title":"ConversationAlign","text":"Lewis, David D., et al. (2004) “Rcv1: new benchmark collection text categorization research.” Journal machine learning research 5: 361-397.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/align_dyads.html","id":null,"dir":"Reference","previous_headings":"","what":"align_dyads — align_dyads","title":"align_dyads — align_dyads","text":"Yokes user-specified semantic, affective, phonological values word cleaned language transcript. Values aligned individual word, words present database dropped. number words dropped reported interlocutor dyad. Reports exchange count, counts pair turns.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/align_dyads.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"align_dyads — align_dyads","text":"","code":"align_dyads(clean_ts_df)"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/align_dyads.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"align_dyads — align_dyads","text":"clean_ts_df dataframe cleaned formatted clean_dyads() function","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/align_dyads.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"align_dyads — align_dyads","text":"dataframe one-word-per-row format variables interest appended","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/clean_dyads.html","id":null,"dir":"Reference","previous_headings":"","what":"clean_dyads — clean_dyads","title":"clean_dyads — clean_dyads","text":"Cleans formats language transcripts read stage. Removes non-alphabetic characters stopwords. Language transcripts can lemmatized calling lemmatize = TRUE. Vectorizes utterance reports total word count mean word length interlocutor dyad. Also reports number words turn.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/clean_dyads.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"clean_dyads — clean_dyads","text":"","code":"clean_dyads(read_ts_df, lemmatize = TRUE, stop_words_df = \"default\")"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/clean_dyads.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"clean_dyads — clean_dyads","text":"read_ts_df data frame produced read_dyads() function lemmatize logical, words lemmatized (switched base morphological form) stop_words_df defaults built list stopwords, otherwise supply file path cvs file column stopwords titles 'Word'","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/clean_dyads.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"clean_dyads — clean_dyads","text":"dataframe cleaned text data, formatted one word per row","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/read_dyads.html","id":null,"dir":"Reference","previous_headings":"","what":"read_dyads — read_dyads","title":"read_dyads — read_dyads","text":"Reads pre-formatted dyadic (2 interlocutor) conversation transcripts machine. Transcripts must either csv txt format. supplying txt file, transcript must formatted otter.ai txt file export. options using csv files flexible. ConversationAlign minimally requires csv file two columns, denoting interlocutor text. separate conversation transcript saved separate file. ConversationAlign use file names document ID. Within read dyads function, set folder_name argument directory path local folder containing transcripts machine (e.g., \"my_transcripts\"). Please see github page examples properly formatted transcripts: https://github.com/Reilly-ConceptsCognitionLab/ConversationAlign","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/read_dyads.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"read_dyads — read_dyads","text":"","code":"read_dyads(folder_name = \"my_transcripts\")"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/read_dyads.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"read_dyads — read_dyads","text":"folder_name folder conversation transcripts csv txt format","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/read_dyads.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"read_dyads — read_dyads","text":"concatenated dataframe language transcript saved separate 'event_id'","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/summarize_dyads.html","id":null,"dir":"Reference","previous_headings":"","what":"summarize_dyads — summarize_dyads","title":"summarize_dyads — summarize_dyads","text":"Calculates appends 3 measures quantifying alignment. Appends mean score dimension turn. Calculates Spearman's rank correlation interlocutor time series appends transcript. Calculates area curve absolute difference time series interlocutor time series. length difference time series can standardized shortest number exchanges present group using internally defined resampling function, called resample = TRUE. Spearman's rank correlation area curve become less reliable dyads 30 exchanges.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/summarize_dyads.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"summarize_dyads — summarize_dyads","text":"","code":"summarize_dyads(aligned_ts_df, resample = TRUE)"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/summarize_dyads.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"summarize_dyads — summarize_dyads","text":"aligned_ts_df produced align_dyads function resample logical, transcript time series downsampled shortest length corpus","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/summarize_dyads_auc.html","id":null,"dir":"Reference","previous_headings":"","what":"summarize_dyads_auc — summarize_dyads_auc","title":"summarize_dyads_auc — summarize_dyads_auc","text":"Calculates area curve absolute difference time series interlocutor time series. length difference time series can standardized shortest number exchanges present group using internally defined resampling function, called resample = TRUE. Area curve become less reliable dyads 30 exchanges.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/summarize_dyads_auc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"summarize_dyads_auc — summarize_dyads_auc","text":"","code":"summarize_dyads_auc(aligned_ts_df, resample = TRUE)"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/summarize_dyads_auc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"summarize_dyads_auc — summarize_dyads_auc","text":"aligned_ts_df data frame produced align_dyads function resample logical, transcript time series downsampled shortest length corpus","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/summarize_dyads_auc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"summarize_dyads_auc — summarize_dyads_auc","text":"data frame associating transcript dAUC calculated dimension","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/summarize_dyads_covar.html","id":null,"dir":"Reference","previous_headings":"","what":"summarize_dyads_covar — summarize_dyads_covar","title":"summarize_dyads_covar — summarize_dyads_covar","text":"Calculates Spearman rank correlation lagged Pearson correlation interlocutor time series dimension transcript.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/summarize_dyads_covar.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"summarize_dyads_covar — summarize_dyads_covar","text":"","code":"summarize_dyads_covar(aligned_ts_df, lags = c(-3, -2, -1, 0, 1, 2, 3))"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/summarize_dyads_covar.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"summarize_dyads_covar — summarize_dyads_covar","text":"aligned_ts_df data frame produced align_dyads function lags vector signed integers specifying lags included Pearson correlation. Negative integers used leads.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/summarize_dyads_covar.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"summarize_dyads_covar — summarize_dyads_covar","text":"data frame containing Spearman Pearson correlation transcript. Results organized column data pivoted longer dimension readability.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/summarize_dyads_slope.html","id":null,"dir":"Reference","previous_headings":"","what":"summarize_dyads_slope — summarize_dyads_slope","title":"summarize_dyads_slope — summarize_dyads_slope","text":"Calculates intercept slope simple linear regression interlocutor difference time series .","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/summarize_dyads_slope.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"summarize_dyads_slope — summarize_dyads_slope","text":"","code":"summarize_dyads_slope(aligned_ts_df)"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/summarize_dyads_slope.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"summarize_dyads_slope — summarize_dyads_slope","text":"aligned_ts_df data frame produced align_dyads function","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/summarize_dyads_slope.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"summarize_dyads_slope — summarize_dyads_slope","text":"data frame containing intercept slope linear regression difference interlocutor time series dimension","code":""}]
