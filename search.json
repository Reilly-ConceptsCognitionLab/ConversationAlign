[{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Jamie Reilly. Author, maintainer. Virginia Ulichney. Author. Ben Sacks. Author. Anna Duncan. Contributor. Sarah Weinstein. Contributor. Tania Giovannetti. Contributor. Chelsea Helion. Contributor.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Reilly J, Ulichney V, Sacks B (2023). ConversationAlign: ConversationAlign. https://reilly-conceptscognitionlab.github.io/ConversationAlign, https://reilly-conceptscognitionlab.github.io/ConversationAlign/.","code":"@Manual{,   title = {ConversationAlign: ConversationAlign},   author = {Jamie Reilly and Virginia Ulichney and Ben Sacks},   year = {2023},   note = {https://reilly-conceptscognitionlab.github.io/ConversationAlign, https://reilly-conceptscognitionlab.github.io/ConversationAlign/}, }"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"conversationalign","dir":"","previous_headings":"","what":"ConversationAlign","title":"ConversationAlign","text":"ConversationAlign analyzes alignment interlocutors (conversation partners) engaged two-person conversations. ConversationAlign works language transcripts. can handle text files (.txt) comma separated value (.csv) spreadsheet style files. ConversationAlign transforms raw language data simultaneous time series objects spanning 30 possible dimensions via embedded lookup database. October 2023: ConversationAlign working, repaired bugs. However, recommend now check one authors maintainers package running largescale analyses. can talk potential hiccups roadblocks given nature particular data.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"ConversationAlign","text":"’s schematic guts program… overview ConversationAlign","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"before-starting-prep-your-data","dir":"","previous_headings":"","what":"Before starting: Prep your data","title":"ConversationAlign","text":"ConversationAlign can handle home brew preferred format. However, transcripts must following header columns bare minimum:  1) Participant identifier (named Interlocutor’, ‘Speaker’, ‘Participant’)  2) Text (named ‘Text’, ‘Utterance’, ‘Turn’) order columns matter. data transcripts (e.g., metadata, timestamps, grouping variables) retained. ’s example transcript work. Don’t worry stripping punctuation. .  Considerations prepping language transcripts ConversationAlign: Save conversation transcript separate file (e.g., MaryJoe_FirstDateTalk.txt) careful/deliberate filenaming convention. filename conversation become event ID dataframe Move language transcripts analyzed one folder (e.g., “my_transcripts”) directory running R script. metadata (e.g., age, timestamps, grouping variables), can either append original transcript merge metdata separate file. useful option many individual difference demographic details.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"ConversationAlign","text":"Install development version ConversationAlign GitHub entering following console script:","code":"install.packages(\"devtools\") devtools::install_github(\"Reilly-ConceptsCognitionLab/ConversationAlign\")"},{"path":[]},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"read_dyads","dir":"","previous_headings":"","what":"read_dyads()","title":"ConversationAlign","text":"function read files concatenate single dataframe, appending document IDs. can call dataframe whatever like. ‘read_dyads’ default reading csv txt files folder called my_transcripts. Just remember finished processing set transcripts, make sure move folder. can think ‘my_transcripts’ staging area loading data ConversationAlign.","code":"MyRawLangSamples <- read_dyads() #if you want to specify a different folder, supply your own path MyRawLangSamples <- read_dyads(\"/my_custompath\")"},{"path":[]},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"clean_dyads","dir":"","previous_headings":"","what":"clean_dyads()","title":"ConversationAlign","text":"‘clean_dyads’ uses numerous regex clean format data just read R previous step. Although many cleaning steps, big ones: 1) lowercase 2) omit stopwords 3) replace contractions (e.g., ‘’re’ ‘’) 4) tick marks apostrophes 5) hypens spaces 6) omits numerals 7) omits/squishes extraneous white space 8) lemmatization ConversationAlign calls textstem package dependency lemmatize language transcript. converts morphologiocal derivatives root forms. default lemmatize=T. Sometimes want retain language output native form. case, change argument clean_dyads lemmatize=F. ‘clean_dyads’ outputs word count metrics pre/post cleaning dyad interlocutor. can useful interested whether one person just doesn’t produce many words produces great deal empty utterances.","code":"MyCleanLangSamples <- clean_dyads(MyRawLangSamples) #default is lemmatize=TRUE #If you do NOT want your language sample lemmatized, change the lemmatize argument to F or FALSE MyCleanLangSamples <- clean_dyads(MyRawLangSamples, lemmatize=FALSE)"},{"path":[]},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"align_dyads","dir":"","previous_headings":"","what":"align_dyads()","title":"ConversationAlign","text":"lot magic happens. align_dyads take cleaned dataframe created last step yoke values every word indexing lookup database. “align” step yokes data word cleaned transcript text structures dataframe speaker (“Participant_ID”), exchange (“exchangecount”), turn (“turncount”) across dyad (“event_id”). prompted select one variables (three) yoke data used later steps compute alignment indices. shown menu wherein can select three variables yoked text. Following menu steps, enter number variable like space separating values (e.g., “10 14 19”). choices: anger, anxiety, boredom, closeness, confusion, dominance, doubt, empathy, encouragement, excitement, guilt, happiness, hope, hostility, politeness, sadness, stress, surprise, trust, valence, age acquisition, word length (letters), morphemes per turn, prevalence (many people know word), number word senses (polysemy), word frequency (lg10), arousal, concreteness, semantic diversity, semantic neighbors. Inspect variable learn scale derivation : https://reilly-lab.github.io/ConversationAlign_VariableLookupKey.pdf ConversationAlign prompt append metadata like add. joins information separate file (e.g., neuropsych scores, ages, etc). Just give ConversationAlign filepath CSV data click “Enter” skip step. metadata file might look like : METADATA IMAGE Run align_dyads cleaned dyads object created using clean_dyads function.","code":"MyAlignedDyads <- align_dyads(MyCleanLangSamples)"},{"path":[]},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"summarize_dyads","dir":"","previous_headings":"","what":"summarize_dyads()","title":"ConversationAlign","text":"last step append two metrics alignment dyad (AUC Spearman R) every variable interest specified. example, summarize_dyads append AUC Spearman values hostility (’s ’re interested ) MaryandMikeFirstDate.  Link read AUC Spearman mean context alignment (look figure illustration): LINK METHOD AUC appear dataframe prefix “auc_”. Spearman’s correlation coefficient appear prefix (“S_rho_”) per variable per dyad.","code":"MyFinalDataframe <- summarize_dyads(MyAlignedDyads) #base function defaults to computing AUC by homogenizing the length of all dyads to the shortest tramscript (number of turns)  MyFinalDataframe <- summarize_dyads(MyAlignedDyads, resample=F) #turns off resampling and computes AUC on the orignal dyads. This makes it very difficult to compare AUC for dyads of different lengths MyFinalDataframe <- summarize_dyads(MyAlignedDyads, resample=T, threshold=40) #specifies your own threshold for resampling your dyads to. All dyads will be resampled to this threshold"},{"path":[]},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"things-you-must-be-careful-about","dir":"","previous_headings":"","what":"Things you must be careful about","title":"ConversationAlign","text":"analysis language comes assumptions potential bias. example, instances researcher might care morphemes grammatical elements ‘’, ‘’, ‘’, etc.. default ConversationAlign omit stopwords average across open class words (e.g., nouns, verbs) turn interlocutor. specific cases can go wrong. ’s need consider: Stopwords : package omits stopwords. See stopword list like inspect list. included greetings, idioms, filler words, numerals, pronouns omissions list. Lemmatization : package lemmatize language transcripts default. Lemmatization transforms inflected forms (e.g., standing, stands) root dictionary entry (e.g., stand). helps yoking offline values (e.g., happiness, concreteness) word also entails NLP folks refer ‘term aggregation’. However, sometimes might want lemmatize. can easily change option using argument, “lemmatize=FALSE,” clean_dyads function . Sample Size Issue 1: exchange count: program derives correlations AUC dyad metrics alignment. 40 exchanges (80 turns) conversation partners, R value computed 40 data points. conversations less 30 turns, trust R values ConversationAlign outputs. Sample Size Issue 2 : matching lookup database: ConversationAlign works yoking values lookup database word language transcript. variables lots values characterizing many English words. variables (e.g., age acquisition) cover 30k words. word transcript ‘match’ lookup datase, ConversationAlign return NA go average words interlocutor turn. can dangerous many missing values. Beware! Compositionality : ConversationAlign caveman complexity. matches value word word island. Phenomena like polysemy (e.g., bank) modulation one word intensifier (e.g., terrible) handled. problem many affective measures lexical variables like word length. Resampling AUC : summarize_dyads output AUC values quantifying distance interlocutors dimension specify. AUC vary depending length dyad. Therefore, often necessary resample (downsample) dyads equivalent length. get wonky uninterpretable short exchanges.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"get-in-touch","dir":"","previous_headings":"","what":"Get in touch!","title":"ConversationAlign","text":"Contact jamie_reilly@temple.edu feedback assistance.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/align_dyads.html","id":null,"dir":"Reference","previous_headings":"","what":"align_dyads — align_dyads","title":"align_dyads — align_dyads","text":"Yokes user-specified semantic, affective, phonological values word cleaned language transcript. Prepares dataframe aligned exchange turn across Participant_IDs.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/align_dyads.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"align_dyads — align_dyads","text":"","code":"align_dyads(clean_ts_df)"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/align_dyads.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"align_dyads — align_dyads","text":"clean_ts_df cleaned formatted dataframe ported clean_dyads() step","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/clean_dyads.html","id":null,"dir":"Reference","previous_headings":"","what":"clean_dyads — clean_dyads","title":"clean_dyads — clean_dyads","text":"Cleans Formats raw language transcripts, removing stopwords formatting dataframe alignment steps","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/clean_dyads.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"clean_dyads — clean_dyads","text":"","code":"clean_dyads(read_ts_df, lemmatize = TRUE)"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/clean_dyads.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"clean_dyads — clean_dyads","text":"read_ts_df formatted dataframe ported read_dyads() step","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/hello.html","id":null,"dir":"Reference","previous_headings":"","what":"Hello, World! — hello","title":"Hello, World! — hello","text":"Prints 'Hello, world!'.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/hello.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hello, World! — hello","text":"","code":"hello()"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/hello.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Hello, World! — hello","text":"","code":"hello() #> Error in hello(): could not find function \"hello\""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/read_dyads.html","id":null,"dir":"Reference","previous_headings":"","what":"read_dyads — read_dyads","title":"read_dyads — read_dyads","text":"Reads pre-formatted conversation transcripts txt csv user's machine; user supplies directory path (e.g., \"my_transcripts\") local folder argument function call","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/read_dyads.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"read_dyads — read_dyads","text":"","code":"read_dyads(folder_name = \"my_transcripts\")"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/read_dyads.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"read_dyads — read_dyads","text":"folder_name user can specify folder name directory language transcripts read , default '-transcripts' root","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/read_dyads.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"read_dyads — read_dyads","text":"concatenated dataframe language transcript saved separate 'event_id'; split separate lists discrete operations later steps","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/summarize_dyads.html","id":null,"dir":"Reference","previous_headings":"","what":"summarize_dyads — summarize_dyads","title":"summarize_dyads — summarize_dyads","text":"appends AUC Spearman Rank Correlation indices dyad (event_id) using resampling algoirthm defaults minimum number exchanges across documents entered","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/summarize_dyads.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"summarize_dyads — summarize_dyads","text":"","code":"summarize_dyads(aligned_ts_df, resample = TRUE, threshold = \"min\")"}]
