[{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Jamie Reilly. Author, maintainer. Virginia Ulichney. Author. Ben Sacks. Author. Anna Duncan. Contributor. Sarah Weinstein. Contributor. Tania Giovannetti. Contributor. Chelsea Helion. Contributor.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Reilly J, Ulichney V, Sacks B (2025). ConversationAlign: ConversationAlign. R package version 0.1.0, https://reilly-conceptscognitionlab.github.io/ConversationAlign/, https://reilly-conceptscognitionlab.github.io/ConversationAlign.","code":"@Manual{,   title = {ConversationAlign: ConversationAlign},   author = {Jamie Reilly and Virginia Ulichney and Ben Sacks},   year = {2025},   note = {R package version 0.1.0, https://reilly-conceptscognitionlab.github.io/ConversationAlign/},   url = {https://reilly-conceptscognitionlab.github.io/ConversationAlign}, }"},{"path":"/index.html","id":"conversationalign","dir":"","previous_headings":"","what":"ConversationAlign","title":"ConversationAlign","text":"ConversationAlign analyzes alignment interlocutors (conversation partners) engaged two-person conversations. ConversationAlign works language transcripts. can handle text files (.txt) comma separated value (.csv) spreadsheet style files. ConversationAlign transforms raw language data simultaneous time series objects spanning 30 possible dimensions via embedded lookup database. October 2023: ConversationAlign working, repaired bugs. However, recommend now check one authors maintainers package running largescale analyses. can talk potential hiccups roadblocks given idiosyncratic nature particular data.","code":""},{"path":"/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"ConversationAlign","text":"’s schematic guts program… overview ConversationAlign","code":""},{"path":"/index.html","id":"before-starting-prep-your-data","dir":"","previous_headings":"","what":"Before starting: Prep your data","title":"ConversationAlign","text":"ConversationAlign can handle home brew preferred format. However, transcripts must following header columns bare minimum:  1) Participant identifier (named Interlocutor’, ‘Speaker’, ‘Participant’)  2) Text (named ‘Text’, ‘Utterance’, ‘Turn’) order columns matter. data transcripts (e.g., metadata, timestamps, grouping variables) retained. ’s example transcript work. Don’t worry stripping punctuation. .  Considerations prepping language transcripts ConversationAlign: Save conversation transcript separate file (e.g., MaryJoe_FirstDateTalk.txt) careful/deliberate filenaming convention. filename conversation become event ID dataframe Move language transcripts analyzed one folder (e.g., “my_transcripts”) directory running R script. metadata (e.g., age, timestamps, grouping variables), can either append original transcript merge metdata separate file. useful option many individual difference demographic details.","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"ConversationAlign","text":"Install development version ConversationAlign GitHub entering following console script:","code":"install.packages(\"devtools\") devtools::install_github(\"Reilly-ConceptsCognitionLab/ConversationAlign\")"},{"path":[]},{"path":"/index.html","id":"read_dyads","dir":"","previous_headings":"","what":"read_dyads()","title":"ConversationAlign","text":"function read files concatenate single dataframe, appending document IDs. can call dataframe whatever like. ‘read_dyads’ default reading csv txt files folder called my_transcripts. Just remember finished processing set transcripts, make sure move folder. can think ‘my_transcripts’ staging area loading data ConversationAlign.","code":"MyRawLangSamples <- read_dyads() #if you want to specify a different folder, supply your own path MyRawLangSamples <- read_dyads(\"/my_custompath\")"},{"path":[]},{"path":"/index.html","id":"clean_dyads","dir":"","previous_headings":"","what":"clean_dyads()","title":"ConversationAlign","text":"‘clean_dyads’ uses numerous regex clean format data just read R previous step. Although many cleaning steps, big ones: 1) lowercase 2) omit stopwords 3) replace contractions (e.g., ‘’re’ ‘’) 4) tick marks apostrophes 5) hypens spaces 6) omits numerals 7) omits/squishes extraneous white space 8) lemmatization ConversationAlign calls textstem package dependency lemmatize language transcript. converts morphologiocal derivatives root forms. default lemmatize=T. Sometimes want retain language output native form. case, change argument clean_dyads lemmatize=F. ‘clean_dyads’ outputs word count metrics pre/post cleaning dyad interlocutor. can useful interested whether one person just doesn’t produce many words produces great deal empty utterances.","code":"MyCleanLangSamples <- clean_dyads(MyRawLangSamples) #default is lemmatize=TRUE #If you do NOT want your language sample lemmatized, change the lemmatize argument to F or FALSE MyCleanLangSamples <- clean_dyads(MyRawLangSamples, lemmatize=FALSE)"},{"path":[]},{"path":"/index.html","id":"align_dyads","dir":"","previous_headings":"","what":"align_dyads()","title":"ConversationAlign","text":"lot magic happens. align_dyads take cleaned dataframe created last step yoke values every word indexing lookup database. “align” step yokes data word cleaned transcript text structures dataframe speaker (“Participant_ID”), exchange (“exchangecount”), turn (“turncount”) across dyad (“event_id”). prompted select one variables (three) yoke data used later steps compute alignment indices. shown menu wherein can select three variables yoked text. Following menu steps, enter number variable like space separating values (e.g., “10 14 19”). choices: anger, anxiety, boredom, closeness, confusion, dominance, doubt, empathy, encouragement, excitement, guilt, happiness, hope, hostility, politeness, sadness, stress, surprise, trust, valence, age acquisition, word length (letters), morphemes per turn, prevalence (many people know word), number word senses (polysemy), word frequency (lg10), arousal, concreteness, semantic diversity, semantic neighbors. Variable key : https://reilly-lab.github.io/ConversationAlign_VariableLookupKey.pdf ConversationAlign prompt append metadata like add. joins information separate file (e.g., neuropsych scores, ages, etc). Just give ConversationAlign filepath CSV data click “Enter” skip step. metadata file might look like : METADATA IMAGE Run align_dyads cleaned dyads object created using clean_dyads function.","code":"MyAlignedDyads <- align_dyads(MyCleanLangSamples)"},{"path":"/index.html","id":"appending-metadata","dir":"","previous_headings":"","what":"Appending metadata","title":"ConversationAlign","text":"TBD","code":""},{"path":[]},{"path":"/index.html","id":"summarize_dyads","dir":"","previous_headings":"","what":"summarize_dyads()","title":"ConversationAlign","text":"last step append two metrics alignment dyad (AUC Spearman R) every variable interest specified. example, summarize_dyads append AUC Spearman values hostility (’s ’re interested ) MaryandMikeFirstDate.  Link read AUC Spearman mean context alignment (look figure illustration): LINK METHOD AUC appear dataframe prefix “auc_”. Spearman’s correlation coefficient appear prefix (“S_rho_”) per variable per dyad.","code":"MyFinalDataframe <- summarize_dyads(MyAlignedDyads) #base function defaults to computing AUC by homogenizing the length of all dyads to the shortest tramscript (number of turns)  MyFinalDataframe <- summarize_dyads(MyAlignedDyads, resample=F) #turns off resampling and computes AUC on the orignal dyads. This makes it very difficult to compare AUC for dyads of different lengths MyFinalDataframe <- summarize_dyads(MyAlignedDyads, resample=T, threshold=40) #specifies your own threshold for resampling your dyads to. All dyads will be resampled to this threshold"},{"path":[]},{"path":"/index.html","id":"things-you-must-be-careful-about","dir":"","previous_headings":"","what":"Things you must be careful about","title":"ConversationAlign","text":"analysis language comes assumptions potential bias. example, instances researcher might care morphemes grammatical elements ‘’, ‘’, ‘’, etc.. default ConversationAlign omit stopwords average across open class words (e.g., nouns, verbs) turn interlocutor. specific cases can go wrong. ’s need consider: Stopwords : package omits stopwords. See stopword list like inspect list. included greetings, idioms, filler words, numerals, pronouns omissions list. Lemmatization : package lemmatize language transcripts default. Lemmatization transforms inflected forms (e.g., standing, stands) root dictionary entry (e.g., stand). helps yoking offline values (e.g., happiness, concreteness) word also entails NLP folks refer ‘term aggregation’. However, sometimes might want lemmatize. can easily change option using argument, “lemmatize=FALSE,” clean_dyads function . Sample Size Issue 1: exchange count: program derives correlations AUC dyad metrics alignment. 40 exchanges (80 turns) conversation partners, R value computed 40 data points. conversations less 30 turns, trust R values ConversationAlign outputs. Sample Size Issue 2 : matching lookup database: ConversationAlign works yoking values lookup database word language transcript. variables lots values characterizing many English words. variables (e.g., age acquisition) cover 30k words. word transcript ‘match’ lookup datase, ConversationAlign return NA go average words interlocutor turn. can dangerous many missing values. Beware! Compositionality : ConversationAlign caveman complexity. matches value word word island. Phenomena like polysemy (e.g., bank) modulation one word intensifier (e.g., terrible) handled. problem many affective measures lexical variables like word length. Resampling AUC : summarize_dyads output AUC values quantifying distance interlocutors dimension specify. AUC vary depending length dyad. Therefore, often necessary resample (downsample) dyads equivalent length. get wonky uninterpretable short exchanges.","code":""},{"path":"/index.html","id":"background","dir":"","previous_headings":"","what":"Background","title":"ConversationAlign","text":"documents describing derived stopword list lookup databases. OSF site method paper : https://osf.io/atf5q/ Read created internal lookup_database ConversationAlign : https://reilly-lab.github.io/ConversationAlign_LookupDb_Methods.pdf Read variables included align linking : https://reilly-lab.github.io/ConversationAlign_VariableLookupKey.pdf can read nature stopword list view : https://reilly-lab.github.io/ConversationAlign_StopwordsDb_Methods.pdf","code":""},{"path":"/index.html","id":"get-in-touch","dir":"","previous_headings":"","what":"Get in touch!","title":"ConversationAlign","text":"Contact jamie_reilly@temple.edu feedback assistance.","code":""},{"path":"/reference/align_dyads.html","id":null,"dir":"Reference","previous_headings":"","what":"align_dyads — align_dyads","title":"align_dyads — align_dyads","text":"Yokes user-specified semantic, affective, phonological values word cleaned language transcript. Values aligned individual word, words present database dropped. number words dropped reported interlocutor dyad. Reports exchange count, counts pair turns.","code":""},{"path":"/reference/align_dyads.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"align_dyads — align_dyads","text":"","code":"align_dyads(clean_ts_df)"},{"path":"/reference/align_dyads.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"align_dyads — align_dyads","text":"clean_ts_df dataframe cleaned formatted clean_dyads() function","code":""},{"path":"/reference/align_dyads.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"align_dyads — align_dyads","text":"dataframe one-word-per-row format variables interest appended","code":""},{"path":"/reference/clean_dyads.html","id":null,"dir":"Reference","previous_headings":"","what":"clean_dyads — clean_dyads","title":"clean_dyads — clean_dyads","text":"Cleans formats language transcripts read stage. Removes non-alphabetic characters stopwords. Language transcripts can lemmatized calling lemmatize = TRUE. Vectorizes utterance reports total word count mean word length interlocutor dyad. Also reports number words turn.","code":""},{"path":"/reference/clean_dyads.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"clean_dyads — clean_dyads","text":"","code":"clean_dyads(read_ts_df, lemmatize = TRUE, stop_words_df = \"default\")"},{"path":"/reference/clean_dyads.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"clean_dyads — clean_dyads","text":"read_ts_df produced read_dyads() function lemmatize logical, words lemmatized (switched base morphological form) stop_words_df defaults built list stopwords, otherwise supply file path cvs file column stopwords titles 'Word'","code":""},{"path":"/reference/clean_dyads.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"clean_dyads — clean_dyads","text":"dataframe cleaned text data, formatted one word per row","code":""},{"path":"/reference/read_dyads.html","id":null,"dir":"Reference","previous_headings":"","what":"read_dyads — read_dyads","title":"read_dyads — read_dyads","text":"Reads pre-formatted dyadic (2 interlocutor) conversation transcripts machine. Transcripts must either csv txt format. supplying txt file, transcript must formatted otter.ai txt file export. options using csv files flexible. ConversationAlign minimally requires csv file two columns, denoting interlocutor text. separate conversation transcript saved separate file. ConversationAlign use file names document ID. Within read dyads function, set folder_name argument directory path local folder containing transcripts machine (e.g., \"my_transcripts\"). Please see github page examples properly formatted transcripts: https://github.com/Reilly-ConceptsCognitionLab/ConversationAlign","code":""},{"path":"/reference/read_dyads.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"read_dyads — read_dyads","text":"","code":"read_dyads(folder_name = \"my_transcripts\")"},{"path":"/reference/read_dyads.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"read_dyads — read_dyads","text":"folder_name folder conversation transcripts csv txt format","code":""},{"path":"/reference/read_dyads.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"read_dyads — read_dyads","text":"concatenated dataframe language transcript saved separate 'event_id'","code":""},{"path":"/reference/summarize_dyads.html","id":null,"dir":"Reference","previous_headings":"","what":"summarize_dyads — summarize_dyads","title":"summarize_dyads — summarize_dyads","text":"Calculates appends 3 measures quantifying alignment. Appends mean score dimension turn. Calculates Spearman's rank correlation interlocutor time series appends transcript. Calculates area curve absolute difference time series interlocutor time series. length difference time series can standardized shortest number exchanges present group using internally defined resampling function, called resample = TRUE. Spearman's rank correlation area curve become less reliable dyads 30 exchanges.","code":""},{"path":"/reference/summarize_dyads.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"summarize_dyads — summarize_dyads","text":"","code":"summarize_dyads(aligned_ts_df, resample = TRUE)"},{"path":"/reference/summarize_dyads.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"summarize_dyads — summarize_dyads","text":"aligned_ts_df produced align_dyads function resample logical, transcript time series downsampled shortest length corpus","code":""},{"path":"/reference/summarize_dyads_auc.html","id":null,"dir":"Reference","previous_headings":"","what":"summarize_dyads_auc — summarize_dyads_auc","title":"summarize_dyads_auc — summarize_dyads_auc","text":"Calculates area curve absolute difference time series interlocutor time series. length difference time series can standardized shortest number exchanges present group using internally defined resampling function, called resample = TRUE. Area curve become less reliable dyads 30 exchanges.","code":""},{"path":"/reference/summarize_dyads_auc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"summarize_dyads_auc — summarize_dyads_auc","text":"","code":"summarize_dyads_auc(aligned_ts_df, resample = TRUE)"},{"path":"/reference/summarize_dyads_auc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"summarize_dyads_auc — summarize_dyads_auc","text":"aligned_ts_df produced align_dyads function resample logical, transcript time series downsampled shortest length corpus","code":""},{"path":"/reference/summarize_dyads_auc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"summarize_dyads_auc — summarize_dyads_auc","text":"data frame associating transcript dAUC calculated dimension","code":""},{"path":"/reference/summarize_dyads_covar.html","id":null,"dir":"Reference","previous_headings":"","what":"summarize_dyads_covar — summarize_dyads_covar","title":"summarize_dyads_covar — summarize_dyads_covar","text":"Calculates Spearman rank correlation lagged Pearson correlation interlocutor time series dimension transcript.","code":""},{"path":"/reference/summarize_dyads_covar.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"summarize_dyads_covar — summarize_dyads_covar","text":"","code":"summarize_dyads_covar(aligned_ts_df, lags = c(-3, -2, -1, 0, 1, 2, 3))"},{"path":"/reference/summarize_dyads_covar.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"summarize_dyads_covar — summarize_dyads_covar","text":"aligned_ts_df Dataframe produced align_dyads function lags vector signed integers specifying lags included Pearson correlation. Negative integers used leads.","code":""},{"path":"/reference/summarize_dyads_covar.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"summarize_dyads_covar — summarize_dyads_covar","text":"data frame containing Spearman Pearson correlation transcript. Results organized column data pivoted longer dimension readability.","code":""},{"path":"/reference/summarize_dyads_slope.html","id":null,"dir":"Reference","previous_headings":"","what":"summarize_dyads_slope — summarize_dyads_slope","title":"summarize_dyads_slope — summarize_dyads_slope","text":"Calculates area curve absolute difference time series interlocutor time series. length difference time series can standardized shortest number exchanges present group using internally defined resampling function, called resample = TRUE. Area curve become less reliable dyads 30 exchanges.","code":""},{"path":"/reference/summarize_dyads_slope.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"summarize_dyads_slope — summarize_dyads_slope","text":"","code":"summarize_dyads_slope(aligned_ts_df, resample = TRUE)"},{"path":"/reference/summarize_dyads_slope.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"summarize_dyads_slope — summarize_dyads_slope","text":"aligned_ts_df produced align_dyads function resample logical stating whether time series downsampled shortest length present","code":""},{"path":"/reference/summarize_dyads_slope.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"summarize_dyads_slope — summarize_dyads_slope","text":"data frame containing intercept slope linear regression difference interlocutor time series dimension","code":""}]
