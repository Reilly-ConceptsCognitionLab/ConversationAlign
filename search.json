[{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Jamie Reilly. Author, maintainer. Virginia Ulichney. Author. Ben Sacks. Author. Anna Duncan. Contributor. Sarah Weinstein. Contributor. Tania Giovannetti. Contributor. Chelsea Helion. Contributor.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Reilly J, Ulichney V, Sacks B (2023). ConversationAlign: ConversationAlign. https://reilly-conceptscognitionlab.github.io/ConversationAlign, https://reilly-conceptscognitionlab.github.io/ConversationAlign/.","code":"@Manual{,   title = {ConversationAlign: ConversationAlign},   author = {Jamie Reilly and Virginia Ulichney and Ben Sacks},   year = {2023},   note = {https://reilly-conceptscognitionlab.github.io/ConversationAlign, https://reilly-conceptscognitionlab.github.io/ConversationAlign/}, }"},{"path":[]},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"ConversationAlign","text":"two people conversing ConversationAlign R package analyzing alignment interlocutors (conversation partners) engaged dyadic conversations (two-person conversations). ConversationAlign work one natural language transcripts following file types: txt (text files), csv (comma separated values files), otter.ai transcripts saved txt files. Please note ConversationAlign currently still development. Please use caution now. Last updated: 2023-10-18","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"nuts-and-bolts","dir":"","previous_headings":"","what":"Nuts and bolts","title":"ConversationAlign","text":"overview ConversationAlign ConversationAlign transforms raw language data simultaneous time series objects spanning 40 possible dimensions (affective, lexical, semantic psycholinguistic variables). ’s overview package transforms language time series data computing alignment indices.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"caveats-things-you-must-be-careful-about","dir":"","previous_headings":"","what":"Caveats: Things you must be careful about!","title":"ConversationAlign","text":"analysis language transcripts comes assumptions potential bias. example, instances researcher might care morphemes grammatical elements ‘’, ‘’, ‘’, etc.. default ConversationAlign omit stopwords average across open class words (e.g., nouns, verbs) turn interlocutor. specific cases can go wrong. ’s need consider: Stopwords: package omits stopwords. See stopword list like inspect list. included greetings, idioms, filler words, numerals, pronouns omissions list. Lemmatization: package lemmatize language transcripts default. Lemmatization transforms inflected forms (e.g., standing, stands) root dictionary entry (e.g., stand). helps yoking offline values (e.g., happiness, concreteness) word also entails NLP folks refer ‘term aggregation’. However, sometimes might want lemmatize. can easily change option using argument, “lemmatize=FALSE,” clean_dyads function . Sample Size Issue 1– exchange count: program derives correlations AUC dyad metrics alignment. 40 exchanges (80 turns) conversation partners, R value computed 40 data points. conversations less 30 turns, trust R values ConversationAlign outputs. Sample Size Issue 2 – matching lookup database: ConversationAlign works yoking values lookup database word language transcript. variables lots values characterizing many English words. variables (e.g., age acquisition) cover 13k words. word transcript ‘match’ lookup datase, ConversationAlign return NA go average words interlocutor turn. can dangerous many missing values. Beware! Insensitivity surrounding words: ConversationAlign caveman complexity. matches value word word island. Phenomena like polysemy (e.g., bank) modulation one word intensifier (e.g., terrible) handled. problem many affective measures lexical variables like word length. Interpretation (particularly affective measures): noted prior, ConversationAlign works yoking values lookup database word language transcript. affective measures come database, AffectVec (Raji & deMelo, 2020, DOI: 10.1145/3366423.3380068). AffectVec database created using machine learning techniques generate word embeddings, may consistent human ratings affective intensity provided text. worth carefully considering reading methods used create AffectVec database prior interpreting affective measures, particularly scientific research. Potential reflection human bias: many machine learning/artificial intelligence techniques, methods used create psycholinguistic database measures comprise ConversationAlign lookup database may generate word embedding values reflect human biases calculation (see Caliskan, Bryson, & Narayanan, 2017, DOI: 10.1126/science.aal4230 Hovy & Prabhumoye, 2021, DOI: 10.1111/lnc3.12432 read ).","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"ConversationAlign","text":"Install development version ConversationAlign GitHub entering following console script:","code":"install.packages(\"devtools\") devtools::install_github(\"Reilly-ConceptsCognitionLab/ConversationAlign\")"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"before-you-start","dir":"","previous_headings":"","what":"Before you start","title":"ConversationAlign","text":"ConversationAlign takes natural language transcripts pairs interlocutors. package can handle Otter.ai formatted files, can also handle home brew preferred format long transcript least two columns containing (1) identifiers interlocutors interaction (e.g., speaker names, random participant IDs) (2) raw text interaction. order two columns transcript matter. users may interested analyzing distinguishable dyads, wherein members interlocutor pairs consistently differentiated meaningful characteristic (e.g., student-teacher, parent-child, boss-employee, etc.). Dyads considered distinguishable members can differentiated way, considered indistinguishable interlocutors least one dyad share characteristic (e.g., parent-parent). distinguishable grouping variable, can either prepare separate file metadata (e.g., grouping variable, age, neuropsychological assessment scores) merge finalized dataframe processed ConversationAlign (prompted align_dyads step), can include original raw transcripts retained.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"prep-your-language-transcripts","dir":"","previous_headings":"","what":"Prep your language transcripts","title":"ConversationAlign","text":"ConversationAlign work .txt .csv files. first (header) row transcript must designate interlocutor (person producing output) text. prepping raw transcripts, careful mark columns follows using one options (case-insensitive). order columns matter: 1) ‘Interlocutor’, ‘Speaker’, ‘Participant’ 2) ‘Text’, ‘Utterance’, ‘Turn’  working multiple transcripts, dyadic conversation transcript saved separate file (e.g., MaryJoe_FirstDateTalk.txt MaryJoe_SecondDateTalk.txt). important ConversationAlign read data R, append document IDs, split dyad separate list. ConversationAlign runs many operations dyad ultimately binds data summary dataframe. ConversationAlign marks conversation unique event_id populated filename (deliberate naming!). metadata (e.g., age, timestamps, grouping variables) language transcripts retained. Move raw transcripts folder. default folder name ConversationAlign search machine ‘my_transcripts’. However, want specify folder name ’s fine . call path argument first function called read_dyads().","code":""},{"path":[]},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"read_dyads","dir":"","previous_headings":"","what":"read_dyads()","title":"ConversationAlign","text":"function read files concatenate single dataframe, appending document IDs. can call dataframe whatever like. read_dyads default reading csv txt files folder called my_transcripts. Just remember finished processing set transcripts, make sure move folder. can think ‘my_transcripts’ staging area loading data ConversationAlign.","code":"MyRawLangSamples <- read_dyads() #if you want to specify a different folder, supply your own path MyRawLangSamples <- read_dyads(\"/my_custompath\")"},{"path":[]},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"clean_dyads","dir":"","previous_headings":"","what":"clean_dyads()","title":"ConversationAlign","text":"‘clean_dyads’ uses regular expressions clean format data. Specifically, function puts words lowercase, replaces tick marks apostrophes contractions, replaces contractions complete words (e.g., “can’t” becomes “”), replaces hyphens spaces, omits numeric characters (e.g., “3rd”, “5th”), removes extraneous white space (e.g., ” ” becomes ” “). function also omits stopwords using custom stopword list, lemmatizes (converts words dictionary entries, ”standing”, “stood”, “stands”, “stand” become “stand”) unless specify otherwise (lemmatize=TRUE default). Run ‘clean_dyads’ object just assembled running ‘read_dyads’ function last step. clean_dyads function also provides metrics wordlength, wordcount, words removed clean step.","code":"MyCleanLangSamples <- clean_dyads(MyRawLangSamples) #default is lemmatize=TRUE #If you do NOT want your language sample lemmatized, change the lemmatize argument to F or FALSE MyCleanLangSamples <- clean_dyads(MyRawLangSamples, lemmatize=FALSE)"},{"path":[]},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"align_dyads","dir":"","previous_headings":"","what":"align_dyads()","title":"ConversationAlign","text":"lot magic happens. align_dyads take cleaned dataframe created last step yoke values every word indexing lookup database. database populated published word norms numerous sources (AffectVec affective measures beginning prefix “aff_”, Raji & deMelo, 2020, DOI: 10.1145/3366423.3380068; Kuperman norms Brysbaert norms semantic lexical measures respectively beginning prefixes “sem_” “lex_”, etc.). “align” step yokes data word cleaned transcript text structures dataframe speaker (“Participant_ID”), exchange (“exchangecount”), turn (“turncount”) across dyad (“event_id”). prompted select one variables (three) yoke data used later steps compute alignment indices. shown menu wherein can select three variables yoked text. Following menu steps, enter number variable like space separating values (e.g., “10 14 19”). choices: anger, anxiety, boredom, closeness, confusion, dominance, doubt, empathy, encouragement, excitement, guilt, happiness, hope, hostility, politeness, sadness, stress, surprise, trust, valence, age acquisition, word length (letters), morphemes per turn, prevalence (many people know word), number word senses (polysemy), word frequency (lg10), arousal, concreteness, semantic diversity, semantic neighbors. select variables like yoked text, asked whether metadata like yoked data can supply filepath csv file containing metadata merged aligned data juncture, click “Enter” skip step. Run align_dyads cleaned dyads object created using clean_dyads function.","code":"MyAlignedDyads <- align_dyads(MyCleanLangSamples)"},{"path":[]},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"summarize_dyads","dir":"","previous_headings":"","what":"summarize_dyads()","title":"ConversationAlign","text":"Lastly, using object produced prior align step, can obtain metrics linguistic alignment interlocutors variables yoked text “align”. step, gain metrics (1) means variable per interlocutor per turn (beginning prefix “mean_”), (2) area curve (beginning prefix “auc_”) per variable per dyad per exchange, (3) Spearman’s correlation coefficient (beginning prefix (“S_rho_”) per variable per dyad per exchange. means variable usage calculated per interlocutor per turn dimension within dyad, calculated using “mean” function “base” package R (R Core Team, 2023). AUC denotes area beneath curve absolute difference speakers’ expression variable exchanges interaction across exchanges within dyad, calculated using “AUC” function “DescTools” package R (Signorell et al., https://andrisignorell.github.io/DescTools/). Spearman’s correlation coefficient provides metric overall association two interlocutors’ scores variable language exchanges, calculated using “cor.test(method =”spearman”)” function “stats” package R (R Core Team, 2023). means within dyads, interlocutor independent means variable, interlocutors AUC Spearman’s correlation coefficient one another.","code":"MySummarizedDyads <- summarize_dyads(MyAlignedDyads)"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"get-in-touch","dir":"","previous_headings":"","what":"Get in touch!","title":"ConversationAlign","text":"Contact jamie_reilly@temple.edu feedback assistance.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/align_dyads.html","id":null,"dir":"Reference","previous_headings":"","what":"align_dyads — align_dyads","title":"align_dyads — align_dyads","text":"Yokes user-specified semantic, affective, phonological values word cleaned language transcript. Prepares dataframe aligned exchange turn across Participant_IDs.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/align_dyads.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"align_dyads — align_dyads","text":"","code":"align_dyads(clean_ts_df)"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/align_dyads.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"align_dyads — align_dyads","text":"clean_ts_df cleaned formatted dataframe ported clean_dyads() step","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/clean_dyads.html","id":null,"dir":"Reference","previous_headings":"","what":"clean_dyads — clean_dyads","title":"clean_dyads — clean_dyads","text":"Cleans Formats raw language transcripts, removing stopwords formatting dataframe alignment steps","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/clean_dyads.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"clean_dyads — clean_dyads","text":"","code":"clean_dyads(read_ts_df, lemmatize = TRUE)"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/clean_dyads.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"clean_dyads — clean_dyads","text":"read_ts_df formatted dataframe ported read_dyads() step","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/hello.html","id":null,"dir":"Reference","previous_headings":"","what":"Hello, World! — hello","title":"Hello, World! — hello","text":"Prints 'Hello, world!'.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/hello.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hello, World! — hello","text":"","code":"hello()"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/hello.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Hello, World! — hello","text":"","code":"hello() #> Error in hello(): could not find function \"hello\""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/read_dyads.html","id":null,"dir":"Reference","previous_headings":"","what":"read_dyads — read_dyads","title":"read_dyads — read_dyads","text":"Reads pre-formatted conversation transcripts txt csv user's machine; user supplies directory path (e.g., \"my_transcripts\") local folder argument function call","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/read_dyads.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"read_dyads — read_dyads","text":"","code":"read_dyads(folder_name = \"my_transcripts\")"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/read_dyads.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"read_dyads — read_dyads","text":"folder_name user can specify folder name directory language transcripts read , default '-transcripts' root","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/summarize_dyads.html","id":null,"dir":"Reference","previous_headings":"","what":"summarize_dyads — summarize_dyads","title":"summarize_dyads — summarize_dyads","text":"appends AUC Spearman Rank Correlation indices dyad (event_id) using resampling algoirthm defaults minimum number exchanges across documents entered","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/summarize_dyads.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"summarize_dyads — summarize_dyads","text":"","code":"summarize_dyads(aligned_ts_df, resample_yes_or_no = TRUE, resample_n = \"min\")"}]
