[{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/articles/CA_Intro.html","id":"intro-to-conversationalign","dir":"Articles","previous_headings":"","what":"Intro to ConversationAlign","title":"ConversationAlign Intro","text":"good conversation cooperative endeavor parties modify form content production align . phenomenon known alignment. People align across many dimensions including words choose affective tenor prosody. ConversationAlign measures dynamics lexical use conversation partners across 40 semantic, lexical, phonological, affective dimensions. launching analyses, important use caveats consider.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/articles/CA_Intro.html","id":"caveats-for-using-conversationalign","dir":"Articles","previous_headings":"Intro to ConversationAlign","what":"Caveats for Using ConversationAlign","title":"ConversationAlign Intro","text":"Language analyses often proliferate complexity. Spend extra time keep careful records logical organization system (e.g., smart filenaming, variable keys, formalized processing pipeline). ConversationAlign works dyadic language transcripts (.e., 2-person dialogues). ConversationAlign parse turns automatically. software aggregate words produced one speaker across sentences rows switch occurs ‘speaker’ column. ConversationAlign strip punctuation special characters automatically. ConversationAlign split/vectorize text one-word-per-row format, retaining variable labels. ConversationAlign retain meta-data throughout text processing (e.g., timestamps, grouping variables). ConversationAlign pretty good detecting repairing unconventional font encoding systems, catch everything, find sorts hidden junk copy/paste interview transcripts random websites YouTube. Inspect transcripts make sure think launching complex computational analysis.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/articles/CA_Intro.html","id":"prepare-your-transcripts-outside-of-the-package","dir":"Articles","previous_headings":"Intro to ConversationAlign","what":"Prepare your Transcripts Outside of the Package","title":"ConversationAlign Intro","text":"Save conversation transcript separate file (*.txt, *.csv, Otter *.ai). deliberate filenaming convention. transcript’s filename become unique document identifier (Event_ID) importing ConversationAlign. Store transcripts want analyze folder (e.g., ’/my_transcripts). transcript folder analysis scripts ideally exist within directory. raw comversation transcript MUST nominally contain least two columns, talker/interlocutor text. Name talker/interlocutor column ‘Interlocutor’, ‘Speaker’, ‘Participant’ (case sensitive). Name text column ‘Text’, ‘Utterance’, ‘Turn’ (case sensitive).","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/articles/CA_Intro.html","id":"installation","dir":"Articles","previous_headings":"","what":"Installation","title":"ConversationAlign Intro","text":"Install load development version ConversationAlign GitHub using devtools package.","code":"# Check if devtools is installed, if not install it if (!require(\"devtools\", quietly = TRUE)) {   install.packages(\"devtools\") }  # Load devtools library(devtools)  # Check if ConversationAlign is installed, if not install from GitHub if (!require(\"ConversationAlign\", quietly = TRUE)) {   devtools::install_github(\"Reilly-ConceptsCognitionLab/ConversationAlign\") }  # Load SemanticDistance library(ConversationAlign)"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/articles/CA_Intro.html","id":"calibaration-transcripts-included-in-conversationalign","dir":"Articles","previous_headings":"Installation","what":"Calibaration Transcripts Included in ConversationAlign","title":"ConversationAlign Intro","text":"ConversationAligncontains two sample conversation transcripts pre-load call package. : MaronGross_2013: Interview transcript Marc Maron Terry Gross NPR (2013). NurseryRhymes: Three nursery rhymes looping phrases formatted conversations, cleaned, aligned illustrate formatting pipeline reshaopes conversation transcripts.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/articles/CA_Intro.html","id":"nurseryrhymes","dir":"Articles","previous_headings":"Installation > Calibaration Transcripts Included in ConversationAlign","what":"NurseryRhymes","title":"ConversationAlign Intro","text":"","code":"knitr::kable(head(NurseryRhymes, 20), format = \"simple\") str(NurseryRhymes) #> 'data.frame':    228 obs. of  3 variables: #>  $ Event_ID      : chr  \"ItsySpider\" \"ItsySpider\" \"ItsySpider\" \"ItsySpider\" ... #>  $ Participant_ID: chr  \"Yin\" \"Maya\" \"Yin\" \"Maya\" ... #>  $ Text_Raw      : chr  \"The itsy-bitsy spider climbed up the water spout\" \"Down came the rain and washed the spider out\" \"Out came the sun, and dried up all the rain\" \"And the itsy-bitsy spider climbed up the spout again\" ..."},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/articles/CA_Intro.html","id":"maron-gross-interview","dir":"Articles","previous_headings":"Installation > Calibaration Transcripts Included in ConversationAlign","what":"Maron-Gross Interview","title":"ConversationAlign Intro","text":"’s one 2013 NPR interview (USA) Marc Maron Terry Gross, titled Marc Maron: Life Fueled ‘Panic Dread’.","code":"knitr::kable(head(MaronGross_2013, 20), format = \"simple\") str(MaronGross_2013) #> 'data.frame':    546 obs. of  2 variables: #>  $ speaker: chr  \"MARON\" \"MARON\" \"MARON\" \"GROSS\" ... #>  $ text   : chr  \" I'm a little nervous but I've prepared I've written things on a piece of paper\" \" I don't know how you prepare I could ask you that - maybe I will But this is how I prepare - I panic\" \" For a while\" \" Yeah\" ..."},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/articles/CA_Intro.html","id":"caveat-emptor","dir":"Articles","previous_headings":"","what":"Caveat emptor","title":"ConversationAlign Intro","text":"analysis language comes assumptions potential bias. example, instances researcher might care morphemes grammatical elements ‘’, ‘’, ‘’, etc.. default ConversationAlign omit stopwords average across open class words (e.g., nouns, verbs) turn interlocutor. specific cases can go wrong. things consider: Stopwords : ConversationAlign omits stopwords default applying customized stopword list, Temple_Stopwords25. CLICK inspect list. stopword list includes greetings, idioms, filler words, numerals, pronouns. Lemmatization : package lemmatize language transcripts default. Lemmatization transforms inflected forms (e.g., standing, stands) root dictionary entry (e.g., stand). helps yoking offline values (e.g., happiness, concreteness) word also entails NLP folks refer ‘term aggregation’. However, sometimes might want lemmatize. can easily change option using argument, “lemmatize=FALSE,” clean_dyads function . Sample Size Issue 1: Exchange Count: program derives correlations AUC dyad metrics alignment. brief conversations (<30 turns), likelihood unstable unreliable estimates high. Sample Size Issue 2 : matching lookup database: ConversationAlign works yoking values lookup database word language transcript. variables lots values characterizing many English words. variables (e.g., age acquisition) cover 30k words. word transcript ‘match’ lookup datase, ConversationAlign return NA go average words interlocutor turn. can dangerous many missing values. Beware! Compositionality : ConversationAlign caveman complexity. matches value word word island. Phenomena like polysemy (e.g., bank) modulation one word intensifier (e.g., terrible) handled. problem many affective measures lexical variables like word length.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/articles/CA_Intro.html","id":"background-and-supporting-materials","dir":"Articles","previous_headings":"","what":"Background and Supporting Materials","title":"ConversationAlign Intro","text":"Preprint  PsyArXiv preprint describing method(s) greater detail referenced : Sacks, B., Ulichney, V., Duncan, ., Helion, C., Weinstein, S., Giovannetti, T., … Reilly, J. (2025, March 12). ConversationAlign: Open-Source Software Analyzing Patterns Lexical Use Alignment Conversation Transcripts. Click read preprint. recently invited revision Behavior Rsearch Methods. update /eventually accepted ! Methods creating internal lookup database  ConversationAlign contains large, internal lexical lookup_database. Click see created merging offline psycholinguistic databases one. Variable Key ConversationAlign  ConversationAlign currently allows users compute alignment dynamics across >40 different lexical, affective, semantic dimensions.Click link variable key.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/articles/CA_Intro.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"ConversationAlign Intro","text":"Lewis, David D., et al. (2004) “Rcv1: new benchmark collection text categorization research.” Journal machine learning research 5: 361-397.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/articles/CA_Step1_Read.html","id":"reading-data-into-r-for-conversationalign","dir":"Articles","previous_headings":"","what":"Reading data into R for ConversationAlign","title":"CA Step 1 Read_Dyads","text":"Half battle R getting data imported formatted. especially true string data working text. ConversationAlign uses series sequential functions import, clean, format raw data. MUST run functions. append important variable names automatically reshape data.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/articles/CA_Step1_Read.html","id":"prepping-your-data-for-import","dir":"Articles","previous_headings":"","what":"Prepping your data for import","title":"CA Step 1 Read_Dyads","text":"ConversationAlign works dyadic (.e., two person) conversation transcripts. transcript must nominally contain two colummns, one column delineate interlocutor (person produced text), another column contain text . ConversationAlign contains import function called read_dyads() scan target folder text samples. read_dyads() import transcripts R concatenate single dataframe. read_dyads() append transcript’s filename unique identifier conversation. SUPER important remember analyzing data. Store individual conversation transcripts (.csv, .txt, .ai) wish concatenate corpus folder. ConversationAlign search folder called my_transcripts directory script. However, feel free name folder anything like. can specify custom path argument read_dyads() transcript must nominally contain two columns data (Participant Text). columns (e.g., meta-data) retained.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/articles/CA_Step1_Read.html","id":"read_dyads","dir":"Articles","previous_headings":"Prepping your data for import","what":"read_dyads()","title":"CA Step 1 Read_Dyads","text":"exampples read_dyads() action. one argument read_dyads(), my_path. supplying quoted directory path folder transcripts live. Remember treat folder staging area! finished set transcripts don’t want read ConversationAlign move folder, specify new folder. Language data tends proliferate quickly, easy forget . CAREFUL secretary, record steps. Arguments read_dyads include:  1. my_path: default ‘my_transcripts’, change path folder name","code":"#will search for folder 'my_transcripts' in your current directory MyConvos <- read_dyads()  #will scan custom folder called 'MyStuff' in your current directory, concatenating all files in that folder into a single dataframe MyConvos2 <- read_dyads(my_path='/MyStuff')"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/articles/CA_Step1_Read.html","id":"read_1file","dir":"Articles","previous_headings":"Prepping your data for import","what":"read_1file()","title":"CA Step 1 Read_Dyads","text":"Read single transcript already R environment. use read_1file() prep Marc Maron Terry Gross transcript. Look column headers changed object name (MaronGross_2013) now Event_ID (document identifier), Arguments read_1file include:  1. my_dat: object already R environment containing text speaker information.","code":"MaryLittleLamb <- read_1file(MaronGross_2013) #print first ten rows of header knitr::kable(head(MaronGross_2013, 15), format = \"pipe\")"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/articles/CA_Step2_Prep.html","id":"cleaning-formatting-aligning-norms-to-your-data","dir":"Articles","previous_headings":"","what":"Cleaning, Formatting, Aligning Norms to Your Data","title":"CA Step 2 Prep Data","text":"Lots wild operations happen next step transform unstructured text numeric time series objects aggregated conversation interlocutor. important handle prep_dyads() processes lemmatization stopword removal mean. prep_dyads() uses numerous regex clean format data just read R previous step. ConversationAlign applies ordered sequence cleaning steps road toward vectorizing original text one-word-per row format. steps include: converting text lowercase, expanding contractions, omitting non-alphabetic characters (e.g., numbers, punctuation, line breaks). addition text cleaning, users guide options stopword removal lemmatization. formatting prep_dyads() prompt select three variables computing alignment . works joining values large internal lookup database word language transcript. prep_dyads() customizable via following arguments.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/articles/CA_Step2_Prep.html","id":"stopword-removal","dir":"Articles","previous_headings":"Cleaning, Formatting, Aligning Norms to Your Data","what":"Stopword removal","title":"CA Step 2 Prep Data","text":"two important arguments regarding stopword removal. omit_stops specifies whether remove stopwords. which_stopwords specifies stopword list like apply default Temple_stops25. full list choices : none, SMART_stops, CA_orig_stops. MIT_stops, Temple_stops25. Stopword removal important, yet also controversial step text cleaning.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/articles/CA_Step2_Prep.html","id":"lemmatization","dir":"Articles","previous_headings":"Cleaning, Formatting, Aligning Norms to Your Data","what":"Lemmatization","title":"CA Step 2 Prep Data","text":"ConversationAlign calls textstem package dependency lemmatize language transcript. converts morphologiocal derivatives root forms. default lemmatize=T. Sometimes want retain language output native form. case, change argument clean_dyads lemmatize=F. clean_dyads() outputs word count metrics pre/post cleaning dyad interlocutor. can useful interested whether one person just doesn’t produce many words produces great deal empty utterances.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/articles/CA_Step2_Prep.html","id":"dimension-selection","dir":"Articles","previous_headings":"Cleaning, Formatting, Aligning Norms to Your Data","what":"Dimension Selection","title":"CA Step 2 Prep Data","text":"magic happens. prep_dyads() yoke published norms >40 possible dimensions every content word transcript (3 time). join executed merging vectorized conversation transcript huge internal lexical database norms spanning 100k English words. prep_dyads() prompt select anywhere 1 3 target dimensions time. Enter number corresponding dimension interest separated spaces hit enter (e.g., 10 14 19) ConversationAlign append published norm available (e.g., concreteness, word length) every running word transcript. quantitative values used subsequent summarize_dyads() step compute alignment.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/articles/CA_Step2_Prep.html","id":"prep_dyads","dir":"Articles","previous_headings":"","what":"prep_dyads()","title":"CA Step 2 Prep Data","text":"-Cleans, formats, vectorizes conversation transwcripts one-word-per-row format -Yokes psycholinguistic norms three dimensions time (<40 possible dimensions) content word. -Retains metadata Arguments prep_dyads:  1) dat_read= name dataframe created read_dyads()  2) omit_stops= T/F (default=T) option remove stopwords 3) lemmatize= lemmatize strings converting entry dictionary form, default lemmatize=TRUE  4) which_stoplist= quoted argument specifying stopword list, options include none, MIT_stops, SMART, CA_OriginalStops, Temple_stops25. Default Temple_stops25","code":"#Example of running the function NurseryRhymes_Prepped <- prep_dyads(dat_read=NurseryRhymes, lemmatize=TRUE, omit_stops=T, which_stoplist=\"Temple_stops25\")"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/articles/CA_Step2_Prep.html","id":"example-of-a-prepped-dataset","dir":"Articles","previous_headings":"prep_dyads()","what":"Example of a prepped dataset","title":"CA Step 2 Prep Data","text":"embedded external data package ‘anger’ values yoked word.","code":"knitr::kable(head(NurseryRhymes_Prepped, 20), format = \"simple\", digits=2)"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/articles/CA_Step3_Summarize.html","id":"summarize_dyads","dir":"Articles","previous_headings":"","what":"summarize_dyads()","title":"CA Step 3 Summarize Dyads","text":"final step ConversationAlign compute summary statistics including main effects alignment statistics vectorized dataframe produced using prep_dyads(). Users several options output data, choices guided analysis strategy. example, linear mixed effects approach might involve modeling rise fall values across turns. contrast, standard ANOVA work grouped summary data. Main effects dimension interest aggregated Conversation (Event_ID) Person (Participant_ID). example, main effects concreteness involve aggregated means concreteness values words produced Mary vs words produced Dave individual conversation. dAUC_raw: difference area curve reflecting difference interlocutors turn dimension uncorrected conversation length. example, Mary’s concreteness Exchange 1 8 (scale 0-9), Dave’s concreteness Exchange 1 4, difference Mary Dave one-turn conversation 4. dAUC reflects area across turns estimated using trapezoidal rule. dAUC_scaled100: normalized AUC value 100 turns using proportional scaling. e.g., (Observed AUC/Turns Raw) = (Normalized AUC)/100). Lead_Corr2: Pearson Spearman lagged correlation reflecting turn--turn covariance across partners specified dimension Lag_Corr2: Lead correlation Who_Talked_First: Interlocutor started conversation (needed interepreting lead/lag stats) Arguments summarize_dyads() include:  1) df_prep= dataframe created prep_dyads()function  2) custom_lags= default NULL, additional user-specified lagged correlations. automatically produce lead 2 turns, immediate response, lag 2 turns dimension interest.  3) sumdat_only= boolean default TRUE, produces grouped summary dataframe averages conversation participant alignment dimension, FALSE retrains original rows, filling empty rows summary statistics conversation (e.g., AUC)  4) corr_type= default=‘Pearson’, option ‘Spearman’ computing turn--turn correlations across interlocutors dimension interest.","code":"MarySumDat <- summarize_dyads(df_prep = NurseryRhymes_Prepped, custom_lags=NULL, sumdat_only = TRUE, corr_type='Pearson')  colnames(MarySumDat) #>  [1] \"Event_ID\"           \"Participant_ID\"     \"Dimension\"          #>  [4] \"Dimension_Mean\"     \"AUC_raw\"            \"AUC_scaled100\"      #>  [7] \"Talked_First\"       \"TurnCorr_Lead2\"     \"TurnCorr_Immediate\" #> [10] \"TurnCorr_Lag2\" knitr::kable(head(MarySumDat, 15), format = \"simple\", digits = 3)"},{"path":[]},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/articles/CA_Step4_Analytics.html","id":"corpus_analytics","dir":"Articles","previous_headings":"Generate corpus analytics","what":"corpus_analytics()","title":"CA Step 4 Corpus Analytics","text":"helpful addition ConversationAlign generate variety corpus analytics (e.g., word count, type-token-ratio) conversation corpus. output summary table readily exportable specific journal format choice using number packages flextable tinytable. Generate corpus analytics dataframe created prep_dyads. Arguments corpus_analytics include:  1) dat_prep= dataframe created prep_dyads()function `","code":"NurseryRhymes_Analytics <-  corpus_analytics(dat_prep=NurseryRhymes_Prepped) knitr::kable(head(NurseryRhymes_Analytics, 15), format = \"simple\", digits = 2)"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Jamie Reilly. Author, maintainer. Virginia Ulichney. Author. Ben Sacks. Author. Sarah Weinstein. Contributor. Chelsea Helion. Contributor. Gus Cooney. Contributor.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Reilly J, Ulichney V, Sacks B (2025). ConversationAlign: Process Text Compute Linguistic Alignment Conversation Transcripts. R package version 0.2.0, https://github.com/Reilly-ConceptsCognitionLab/ConversationAlign.","code":"@Manual{,   title = {ConversationAlign: Process Text and Compute Linguistic Alignment in Conversation Transcripts},   author = {Jamie Reilly and Virginia Ulichney and Ben Sacks},   year = {2025},   note = {R package version 0.2.0},   url = {https://github.com/Reilly-ConceptsCognitionLab/ConversationAlign}, }"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"conversationalign","dir":"","previous_headings":"","what":"Process Text and Compute Linguistic Alignment in Conversation Transcripts","title":"Process Text and Compute Linguistic Alignment in Conversation Transcripts","text":"Open-source software computing main effects indices alignment across coversation partners dyadic conversation transcripts.","code":""},{"path":[]},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"Process Text and Compute Linguistic Alignment in Conversation Transcripts","text":"ConversationAlign analyzes alignment computes main effects across 40 unique dimensions interlocutors (conversation partners) engaged two-person conversations. ConversationAlign transforms raw language data simultaneous time series objects across >40 possible dimensions via embedded lookup database. number issues consider steps take prepare data.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"installation-and-technical-considerations","dir":"","previous_headings":"","what":"Installation and Technical Considerations","title":"Process Text and Compute Linguistic Alignment in Conversation Transcripts","text":"One main features ConversationAlign algorithm involves yoking norms many different lexical, affective, semantic dimensions content word conversation transcripts interest. accomplish joining data several large lookup databases. databases large embed within ConversationAlign. load ConversationAlign, databases automatically download load external companionn repository ConversationAlign_Data. ConversationAlign needs data, need decent internet connection load package. might take second two complete download Github acting . Install development version ConversationAlign GitHub using devtools package.","code":"# Check if devtools is installed, if not install it if (!require(\"devtools\", quietly = TRUE)) {   install.packages(\"devtools\") }  # Load devtools library(devtools)  # Check if ConversationAlign is installed, if not install from GitHub if (!require(\"ConversationAlign\", quietly = TRUE)) {   devtools::install_github(\"Reilly-ConceptsCognitionLab/ConversationAlign\") }  # Load SemanticDistance library(ConversationAlign)"},{"path":[]},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"read_dyads","dir":"","previous_headings":"","what":"read_dyads()","title":"Process Text and Compute Linguistic Alignment in Conversation Transcripts","text":"Reads transcripts local drive directory choice. Store individual conversation transcripts (.csv, .txt, .ai) wish concatenate corpus folder. ConversationAlign search folder called my_transcripts directory script. However, feel free name folder anything like. can specify custom path argument read_dyads() transcript must nominally contain two columns data (Participant Text). columns (e.g., meta-data) retained.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"arguments-to-read_dyads--","dir":"","previous_headings":"read_dyads()","what":"Arguments to read_dyads:","title":"Process Text and Compute Linguistic Alignment in Conversation Transcripts","text":"my_path default ‘my_transcripts’, change path folder name","code":"#will search for folder 'my_transcripts' in your current directory MyConvos <- read_dyads()  #will scan custom folder called 'MyStuff' in your current directory, concatenating all files in that folder into a single dataframe MyConvos2 <- read_dyads(my_path='/MyStuff')"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"read_1file","dir":"","previous_headings":"","what":"read_1file()","title":"Process Text and Compute Linguistic Alignment in Conversation Transcripts","text":"Read single transcript already R environment. use read_1file() prep Marc Maron Terry Gross transcript. Look column headers changed object name (MaronGross_2013) now Event_ID (document identifier),","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"arguments-to-read_1file--","dir":"","previous_headings":"read_1file()","what":"Arguments to read_1file:","title":"Process Text and Compute Linguistic Alignment in Conversation Transcripts","text":"my_dat object already R environment containing text speaker information.","code":"MaryLittleLamb <- read_1file(MaronGross_2013) #print first ten rows of header knitr::kable(head(MaronGross_2013, 10), format = \"pipe\")"},{"path":[]},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"prep_dyads","dir":"","previous_headings":"","what":"prep_dyads()","title":"Process Text and Compute Linguistic Alignment in Conversation Transcripts","text":"-Cleans, formats, vectorizes conversation transwcripts one-word-per-row format -Yokes psycholinguistic norms three dimensions time (<40 possible dimensions) content word. -Retains metadata","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"arguments-to-prep_dyads--","dir":"","previous_headings":"prep_dyads()","what":"Arguments to prep_dyads():","title":"Process Text and Compute Linguistic Alignment in Conversation Transcripts","text":"dat_read name dataframe created read_dyads() omit_stops T/F (default=T) option remove stopwords lemmatize T/F (default=T) lemmatize strings converting entry dictionary form which_stoplist quoted argument specifying stopword list apply, options include none, MIT_stops, SMART_stops, CA_OriginalStops, Temple_stops25. Default Temple_stops25. Example prepped dataset embedded external data package ‘anger’ values yoked word.","code":"NurseryRhymes_Prepped <- prep_dyads(dat_read=NurseryRhymes, lemmatize=TRUE, omit_stops=T, which_stoplist=\"Temple_stops25\") knitr::kable(head(NurseryRhymes_Prepped, 10), format = \"simple\", digits=2)"},{"path":[]},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"summarize_dyads","dir":"","previous_headings":"","what":"summarize_dyads()","title":"Process Text and Compute Linguistic Alignment in Conversation Transcripts","text":"computational stage package generates dataframe boiled two rows per converation summary data appended level Participant_ID. returns difference time series AUC (dAUC) every variable interest specified correlation lags -2,,0, 2. decide whether want Pearson Spearman lagged correlation.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"arguments-to-summarize_dyads--","dir":"","previous_headings":"summarize_dyads()","what":"Arguments to summarize_dyads():","title":"Process Text and Compute Linguistic Alignment in Conversation Transcripts","text":"df_prep dataframe created prep_dyads() function custom_lags user specifies custom set turn-lags. Default NULL ConversationAlign producing correlations lead 2 turns, immediate response, lag 2 turns dimension interest. sumdat_only default TRUE, produces grouped summary dataframe averages conversation participant alignment dimension, FALSE retrains original rows, filling empty rows summary statistics conversation (e.g., AUC) corr_type specifies correlation madel (parametric default = ‘Pearson’); option ‘Spearman’ computing turn--turn correlations across interlocutors dimension interest.","code":"MarySumDat <- summarize_dyads(df_prep = NurseryRhymes_Prepped, custom_lags=NULL, sumdat_only = TRUE, corr_type='Pearson')  colnames(MarySumDat) #>  [1] \"Event_ID\"           \"Participant_ID\"     \"Dimension\"          #>  [4] \"Dimension_Mean\"     \"AUC_raw\"            \"AUC_scaled100\"      #>  [7] \"Talked_First\"       \"TurnCorr_Lead2\"     \"TurnCorr_Immediate\" #> [10] \"TurnCorr_Lag2\" knitr::kable(head(MarySumDat, 10), format = \"simple\", digits = 3)"},{"path":[]},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"corpus_analytics","dir":"","previous_headings":"","what":"corpus_analytics()","title":"Process Text and Compute Linguistic Alignment in Conversation Transcripts","text":"often critical produce descriptives/summary statistics characterize language sample. typically laborious process. corpus_analytics , generating near publication ready table analytics can easily export specific journal format choice using number packages flextable tinytable.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"arguments-to-corpus_analytics","dir":"","previous_headings":"corpus_analytics()","what":"Arguments to corpus_analytics():","title":"Process Text and Compute Linguistic Alignment in Conversation Transcripts","text":"dat_prep dataframe created prep_dyads()function","code":"NurseryRhymes_Analytics <-  corpus_analytics(dat_prep=NurseryRhymes_Prepped) knitr::kable(head(NurseryRhymes_Analytics, 10), format = \"simple\", digits = 2)"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"news-and-getting-help","dir":"","previous_headings":"","what":"News and Getting Help","title":"Process Text and Compute Linguistic Alignment in Conversation Transcripts","text":"Bugs/Features:Open Issue Questions:Join Discussion Urgent:Email jamie.reilly@temple.edu","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/ConversationAlign-package.html","id":null,"dir":"Reference","previous_headings":"","what":"ConversationAlign: Process Text and Compute Linguistic Alignment in Conversation Transcripts — ConversationAlign-package","title":"ConversationAlign: Process Text and Compute Linguistic Alignment in Conversation Transcripts — ConversationAlign-package","text":"`ConversationAlign` imports conversation transcripts R, concatenates single dataframe appending event identifiers, cleans formats text, yokes user-specified psycholinguistic database values word. `ConversationAlign` computes alignment indices two interlocutors across transcript >40 possible semantic, lexical, affective dimensions. addition alignment, `ConversationAlign` also produces table analytics (e.g., token count, type-token-ratio) summary table describing particular text corpus.","code":""},{"path":[]},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/ConversationAlign-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"ConversationAlign: Process Text and Compute Linguistic Alignment in Conversation Transcripts — ConversationAlign-package","text":"Maintainer: Jamie Reilly jamie_reilly@temple.edu (ORCID) Authors: Virginia Ulichney Ben Sacks contributors: Sarah Weinstein [contributor] Chelsea Helion [contributor] Gus Cooney [contributor]","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/MaronGross_2013.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample Dyadic Interview Transcript: Marc Maron and Terry Gross Radio Interview 2013 — MaronGross_2013","title":"Sample Dyadic Interview Transcript: Marc Maron and Terry Gross Radio Interview 2013 — MaronGross_2013","text":"Text talker information delineated, raw transcript, multiple lines per talker","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/MaronGross_2013.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample Dyadic Interview Transcript: Marc Maron and Terry Gross Radio Interview 2013 — MaronGross_2013","text":"","code":"MaronGross_2013"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/MaronGross_2013.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Sample Dyadic Interview Transcript: Marc Maron and Terry Gross Radio Interview 2013 — MaronGross_2013","text":"## \"MaronGross_2013\" data.frame 546 obs, 2 vars: text text interview speaker speaker identity","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/NurseryRhymes.html","id":null,"dir":"Reference","previous_headings":"","what":"Text and talker information delineated, 3 separate nursery rhymes, good for computing analytics and word counts — NurseryRhymes","title":"Text and talker information delineated, 3 separate nursery rhymes, good for computing analytics and word counts — NurseryRhymes","text":"Text talker information delineated, 3 separate nursery rhymes, good computing analytics word counts","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/NurseryRhymes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Text and talker information delineated, 3 separate nursery rhymes, good for computing analytics and word counts — NurseryRhymes","text":"","code":"NurseryRhymes"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/NurseryRhymes.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Text and talker information delineated, 3 separate nursery rhymes, good for computing analytics and word counts — NurseryRhymes","text":"## \"NurseryRhymes\" data.frame 100 observations, 2 vars: Event_ID factor 3 different simulated conversations Participant_ID fictional speaker names, 2 conversation Text_Raw simulated language production, actually looped phrases nursery rhymes","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/NurseryRhymes_Prepped.html","id":null,"dir":"Reference","previous_headings":"","what":"Text and talker information delineated, 3 separate nursery rhymes, good for computing analytics and word counts — NurseryRhymes_Prepped","title":"Text and talker information delineated, 3 separate nursery rhymes, good for computing analytics and word counts — NurseryRhymes_Prepped","text":"Text talker information delineated, 3 separate nursery rhymes, good computing analytics word counts","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/NurseryRhymes_Prepped.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Text and talker information delineated, 3 separate nursery rhymes, good for computing analytics and word counts — NurseryRhymes_Prepped","text":"","code":"NurseryRhymes_Prepped"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/NurseryRhymes_Prepped.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Text and talker information delineated, 3 separate nursery rhymes, good for computing analytics and word counts — NurseryRhymes_Prepped","text":"## \"NurseryRhymes_Prepped\" data.frame 1507 x 7 observations, 5 vars: Event_ID factor 3 different simulated conversations Participant_ID fictional speaker names, 2 conversation Exchange_Count sequential numbering exchanges conversation, 1 exchange = 2 turns Turn_Count sequential numbering turns conversation Text_Clean content words emo_anger raw value anger salience yoked word","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/corpus_analytics.html","id":null,"dir":"Reference","previous_headings":"","what":"corpus_analytics — corpus_analytics","title":"corpus_analytics — corpus_analytics","text":"Produces table corpus analytics including numbers complete observations step, word counts, lexical diversity (e.g., TTR), stopword ratios, etc. Granularity summary statistics guided user (e.g., conversation, conversation speaker, collapsed )","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/corpus_analytics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"corpus_analytics — corpus_analytics","text":"","code":"corpus_analytics(dat_prep)"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/corpus_analytics.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"corpus_analytics — corpus_analytics","text":"dat_prep takes dataframe produced df_prep() function","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/corpus_analytics.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"corpus_analytics — corpus_analytics","text":"dataframe summary analytics conversation corpus","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/load_github_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Load all .rda files from a GitHub data folder into the package environment — load_github_data","title":"Load all .rda files from a GitHub data folder into the package environment — load_github_data","text":"Load .rda files GitHub data folder package environment","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/load_github_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load all .rda files from a GitHub data folder into the package environment — load_github_data","text":"","code":"load_github_data(   repo = \"Reilly-ConceptsCognitionLab/ConversationAlign_Data\",   branch = \"main\",   data_folder = \"data\",   envir = parent.frame() )"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/load_github_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load all .rda files from a GitHub data folder into the package environment — load_github_data","text":"repo GitHub repository (e.g., \"username/repo\") branch Branch name (default: \"main\") data_folder Remote folder containing .rda files (default: \"data/\") envir Environment load (default: package namespace)","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/load_github_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Load all .rda files from a GitHub data folder into the package environment — load_github_data","text":"Invisible TRUE successful","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/prep_dyads.html","id":null,"dir":"Reference","previous_headings":"","what":"prep_dyads — prep_dyads","title":"prep_dyads — prep_dyads","text":"Cleans, vectorizes appends lexical norms content words language corpus. User guides options stopword removal lemmatization. User selects three psycholinguistic dimensions yoke norms content word transcript.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/prep_dyads.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"prep_dyads — prep_dyads","text":"","code":"prep_dyads(   dat_read,   lemmatize = TRUE,   omit_stops = TRUE,   which_stoplist = \"Temple_stops25\" )"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/prep_dyads.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"prep_dyads — prep_dyads","text":"dat_read data frame produced read_dyads() function lemmatize logical, words lemmatized (switched base morphological form), default TRUE omit_stops remove stopwords, default TRUE which_stoplist user specifies stopword removal method options including \"none\", \"SMART\", \"MIT_stops\", \"CA_OriginalStops\", \"Temple_Stopwords25\". \"Temple_Stopwords25 default list","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/prep_dyads.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"prep_dyads — prep_dyads","text":"dataframe cleaned text data, formatted one word per row","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/read_1file.html","id":null,"dir":"Reference","previous_headings":"","what":"read_1file — read_1file","title":"read_1file — read_1file","text":"Reads pre-formatted dyadic (2 interlocutor) conversation transcript already imported R environment.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/read_1file.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"read_1file — read_1file","text":"","code":"read_1file(my_dat)"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/read_1file.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"read_1file — read_1file","text":"my_dat conversation transcript csv txt format","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/read_1file.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"read_1file — read_1file","text":"dataframe formatted 'Event_ID', \"Participant_ID\", \"RawText\" – ready clean_dyads()","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/read_dyads.html","id":null,"dir":"Reference","previous_headings":"","what":"read_dyads — read_dyads","title":"read_dyads — read_dyads","text":"Reads pre-formatted dyadic (2 interlocutor) conversation transcripts machine. Transcripts must either csv txt format. supplying txt file, transcript must formatted otter.ai txt file export. options using csv files flexible. ConversationAlign minimally requires csv file two columns, denoting interlocutor text. separate conversation transcript saved separate file. ConversationAlign use file names document ID. Within read dyads function, set my_path argument directory path local folder containing transcripts machine (e.g., \"my_transcripts\"). Please see github page examples properly formatted transcripts: https://github.com/Reilly-ConceptsCognitionLab/ConversationAlign","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/read_dyads.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"read_dyads — read_dyads","text":"","code":"read_dyads(my_path = \"my_transcripts\")"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/read_dyads.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"read_dyads — read_dyads","text":"my_path folder conversation transcripts csv txt format","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/read_dyads.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"read_dyads — read_dyads","text":"concatenated dataframe language transcript saved separate 'event_id'","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/summarize_dyads.html","id":null,"dir":"Reference","previous_headings":"","what":"summarize_dyads — summarize_dyads","title":"summarize_dyads — summarize_dyads","text":"Calculates appends 3 measures quantifying alignment. Appends mean score dimension turn. Calculates Spearman's rank correlation interlocutor time series appends transcript. Calculates area curve absolute difference time series interlocutor time series. length difference time series can standardized shortest number exchanges present group using internally defined resampling function, called resample = TRUE. Spearman's rank correlation area curve become less reliable dyads 30 exchanges.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/summarize_dyads.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"summarize_dyads — summarize_dyads","text":"","code":"summarize_dyads(   df_prep,   custom_lags = NULL,   sumdat_only = TRUE,   corr_type = \"Pearson\" )"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/summarize_dyads.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"summarize_dyads — summarize_dyads","text":"df_prep produced align_dyads function custom_lags integer vector, lags added addition -2, 0, 2 sumdat_only default=TRUE, group summarize data, two rows per conversation, one row participant, false fill summary statistics across exchanges corr_type option computing lagged correlations turn--turn covariance (default='Pearson')","code":""}]
