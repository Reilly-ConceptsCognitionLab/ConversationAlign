[{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/articles/ConversationAlign Introduction.html","id":"caveats-for-using-conversationalign","dir":"Articles","previous_headings":"","what":"Caveats for Using ConversationAlign","title":"ConversationAlign Introduction","text":"Language analyses often proliferate complexity. Spend extra time keep careful records logical organization system (e.g., smart filenaming, variable keys, formalized processing pipeline). ConversationAlign works dyadic language transcripts (.e., 2-person dialogues). ConversationAlign parse turns automatically. software aggregate words produced one speaker across sentences rows switch occurs ‘speaker’ column. ConversationAlign strip punctuation special characters automatically. ConversationAlign split/vectorize text one-word-per-row format, retaining variable labels. ConversationAlign retain meta-data throughout text processing (e.g., timestamps, grouping variables). ConversationAlign pretty good detecting repairing unconventional font encoding systems, catch everything, find sorts hidden junk copy/paste interview transcripts random websites YouTube. Inspect transcripts make sure think launching complex computational analysis.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/articles/ConversationAlign Introduction.html","id":"prepare-your-transcripts-outside-of-the-package","dir":"Articles","previous_headings":"","what":"Prepare your Transcripts Outside of the Package","title":"ConversationAlign Introduction","text":"Save conversation transcript separate file (*.txt, *.csv, Otter *.ai). deliberate filenaming convention. transcript’s filename become unique document identifier (Event_ID) importing ConversationAlign. Store transcripts want analyze folder (e.g., ’/my_transcripts). transcript folder analysis scripts ideally exist within directory. raw comversation transcript MUST nominally contain least two columns, talker/interlocutor text. Name talker/interlocutor column ‘Interlocutor’, ‘Speaker’, ‘Participant’ (case sensitive). Name text column ‘Text’, ‘Utterance’, ‘Turn’ (case sensitive).","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/articles/ConversationAlign Introduction.html","id":"installation","dir":"Articles","previous_headings":"","what":"Installation","title":"ConversationAlign Introduction","text":"Install load development version ConversationAlign GitHub using devtools package.","code":"# Load SemanticDistance library(ConversationAlign)"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/articles/ConversationAlign Introduction.html","id":"calibaration-transcripts-included-in-conversationalign","dir":"Articles","previous_headings":"Installation","what":"Calibaration Transcripts Included in ConversationAlign","title":"ConversationAlign Introduction","text":"ConversationAligncontains two sample conversation transcripts pre-load call package. : MaronGross_2013: Interview transcript Marc Maron Terry Gross NPR (2013). NurseryRhymes: Three nursery rhymes looping phrases formatted conversations, cleaned, aligned illustrate formatting pipeline reshaopes conversation transcripts.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/articles/ConversationAlign Introduction.html","id":"nurseryrhymes","dir":"Articles","previous_headings":"Installation > Calibaration Transcripts Included in ConversationAlign","what":"NurseryRhymes","title":"ConversationAlign Introduction","text":"","code":"knitr::kable(head(NurseryRhymes, 20), format = \"simple\") str(NurseryRhymes) #> 'data.frame':    228 obs. of  3 variables: #>  $ Event_ID      : chr  \"ItsySpider\" \"ItsySpider\" \"ItsySpider\" \"ItsySpider\" ... #>  $ Participant_ID: chr  \"Yin\" \"Maya\" \"Yin\" \"Maya\" ... #>  $ Text_Raw      : chr  \"The itsy-bitsy spider climbed up the water spout\" \"Down came the rain and washed the spider out\" \"Out came the sun, and dried up all the rain\" \"And the itsy-bitsy spider climbed up the spout again\" ..."},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/articles/ConversationAlign Introduction.html","id":"maron-gross-interview","dir":"Articles","previous_headings":"Installation > Calibaration Transcripts Included in ConversationAlign","what":"Maron-Gross Interview","title":"ConversationAlign Introduction","text":"’s one 2013 NPR interview (USA) Marc Maron Terry Gross, titled Marc Maron: Life Fueled ‘Panic Dread’.","code":"knitr::kable(head(MaronGross_2013, 20), format = \"simple\") str(MaronGross_2013) #> 'data.frame':    546 obs. of  2 variables: #>  $ speaker: chr  \"MARON\" \"MARON\" \"MARON\" \"GROSS\" ... #>  $ text   : chr  \" I'm a little nervous but I've prepared I've written things on a piece of paper\" \" I don't know how you prepare I could ask you that - maybe I will But this is how I prepare - I panic\" \" For a while\" \" Yeah\" ..."},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/articles/ConversationAlign Introduction.html","id":"caveat-emptor","dir":"Articles","previous_headings":"","what":"Caveat emptor","title":"ConversationAlign Introduction","text":"analysis language comes assumptions potential bias. example, instances researcher might care morphemes grammatical elements ‘’, ‘’, ‘’, etc.. default ConversationAlign omit stopwords average across open class words (e.g., nouns, verbs) turn interlocutor. specific cases can go wrong. things consider: Stopwords : ConversationAlign omits stopwords default applying customized stopword list, Temple_Stopwords25. CLICK inspect list. stopword list includes greetings, idioms, filler words, numerals, pronouns. Lemmatization : package lemmatize language transcripts default. Lemmatization transforms inflected forms (e.g., standing, stands) root dictionary entry (e.g., stand). helps yoking offline values (e.g., happiness, concreteness) word also entails NLP folks refer ‘term aggregation’. However, sometimes might want lemmatize. can easily change option using argument, “lemmatize=FALSE,” clean_dyads function . Sample Size Issue 1: Exchange Count: program derives correlations AUC dyad metrics alignment. brief conversations (<30 turns), likelihood unstable unreliable estimates high. Sample Size Issue 2 : matching lookup database: ConversationAlign works yoking values lookup database word language transcript. variables lots values characterizing many English words. variables (e.g., age acquisition) cover 30k words. word transcript ‘match’ lookup datase, ConversationAlign return NA go average words interlocutor turn. can dangerous many missing values. Beware! Compositionality : ConversationAlign caveman complexity. matches value word word island. Phenomena like polysemy (e.g., bank) modulation one word intensifier (e.g., terrible) handled. problem many affective measures lexical variables like word length.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/articles/ConversationAlign Introduction.html","id":"background-and-supporting-materials","dir":"Articles","previous_headings":"","what":"Background and Supporting Materials","title":"ConversationAlign Introduction","text":"Preprint  PsyArXiv preprint describing method(s) greater detail referenced : Sacks, B., Ulichney, V., Duncan, ., Helion, C., Weinstein, S., Giovannetti, T., … Reilly, J. (2025, March 12). ConversationAlign: Open-Source Software Analyzing Patterns Lexical Use Alignment Conversation Transcripts. Click read preprint. recently invited revision Behavior Rsearch Methods. update /eventually accepted ! Methods creating internal lookup database  ConversationAlign contains large, internal lexical lookup_database. Click see created merging offline psycholinguistic databases one. Variable Key ConversationAlign  ConversationAlign currently allows users compute alignment dynamics across >40 different lexical, affective, semantic dimensions.Click link variable key.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/articles/ConversationAlign Introduction.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"ConversationAlign Introduction","text":"Lewis, David D., et al. (2004) “Rcv1: new benchmark collection text categorization research.” Journal machine learning research 5: 361-397.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/articles/ConversationAlign Step1 Read.html","id":"reading-data-into-r-for-conversationalign","dir":"Articles","previous_headings":"","what":"Reading data into R for ConversationAlign","title":"ConversationAlign Step1 Read","text":"Half battle R getting data imported formatted. especially true string data working text. ConversationAlign uses series sequential functions import, clean, format raw data. MUST run functions. append important variable names automatically reshape data.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/articles/ConversationAlign Step1 Read.html","id":"prepping-your-data-for-import","dir":"Articles","previous_headings":"","what":"Prepping your data for import","title":"ConversationAlign Step1 Read","text":"ConversationAlign works dyadic (.e., two person) conversation transcripts. transcript must nominally contain two colummns, one column delineate interlocutor (person produced text), another column contain text . ConversationAlign contains import function called read_dyads() scan target folder text samples. read_dyads() import transcripts R concatenate single dataframe. read_dyads() append transcript’s filename unique identifier conversation. SUPER important remember analyzing data. Store individual conversation transcripts (.csv, .txt, .ai) wish concatenate corpus folder. ConversationAlign search folder called my_transcripts directory script. However, feel free name folder anything like. can specify custom path argument read_dyads() transcript must nominally contain two columns data (Participant Text). columns (e.g., meta-data) retained.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/articles/ConversationAlign Step1 Read.html","id":"read_dyads","dir":"Articles","previous_headings":"Prepping your data for import","what":"read_dyads()","title":"ConversationAlign Step1 Read","text":"exampples read_dyads() action. one argument read_dyads(), my_path. supplying quoted directory path folder transcripts live. Remember treat folder staging area! finished set transcripts don’t want read ConversationAlign move folder, specify new folder. Language data tends proliferate quickly, easy forget . CAREFUL secretary, record steps. Arguments read_dyads include:  1. my_path: default ‘my_transcripts’, change path folder name","code":"#will search for folder 'my_transcripts' in your current directory MyConvos <- read_dyads()  #will scan custom folder called 'MyStuff' in your current directory, concatenating all files in that folder into a single dataframe MyConvos2 <- read_dyads(my_path='/MyStuff')"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/articles/ConversationAlign Step1 Read.html","id":"read_1file","dir":"Articles","previous_headings":"Prepping your data for import","what":"read_1file()","title":"ConversationAlign Step1 Read","text":"Read single transcript already R environment. use read_1file() prep Marc Maron Terry Gross transcript. Look column headers changed object name (MaronGross_2013) now Event_ID (document identifier), Arguments read_1file include:  1. my_dat: object already R environment containing text speaker information.","code":"MaryLittleLamb <- read_1file(MaronGross_2013) #print first ten rows of header knitr::kable(head(MaronGross_2013, 15), format = \"pipe\")"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/articles/ConversationAlign Step2 Prep.html","id":"cleaning-formatting-aligning-norms-to-your-data","dir":"Articles","previous_headings":"","what":"Cleaning, Formatting, Aligning Norms to Your Data","title":"ConversationAlign Step2 Prep","text":"Lots wild operations happen next step transform unstructured text numeric time series objects aggregated conversation interlocutor. important handle prep_dyads() processes lemmatization stopword removal mean. prep_dyads() uses numerous regex clean format data just read R previous step. ConversationAlign applies ordered sequence cleaning steps road toward vectorizing original text one-word-per row format. steps include: converting text lowercase, expanding contractions, omitting non-alphabetic characters (e.g., numbers, punctuation, line breaks). addition text cleaning, users guide options stopword removal lemmatization. formatting prep_dyads() prompt select three variables computing alignment . works joining values large internal lookup database word language transcript. prep_dyads() customizable via following arguments.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/articles/ConversationAlign Step2 Prep.html","id":"stopword-removal","dir":"Articles","previous_headings":"Cleaning, Formatting, Aligning Norms to Your Data","what":"Stopword removal","title":"ConversationAlign Step2 Prep","text":"two important arguments regarding stopword removal. omit_stops specifies whether remove stopwords. which_stopwords specifies stopword list like apply default Temple_stops25. full list choices : none, SMART_stops, CA_orig_stops. MIT_stops, Temple_stops25. Stopword removal important, yet also controversial step text cleaning.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/articles/ConversationAlign Step2 Prep.html","id":"lemmatization","dir":"Articles","previous_headings":"Cleaning, Formatting, Aligning Norms to Your Data","what":"Lemmatization","title":"ConversationAlign Step2 Prep","text":"ConversationAlign calls textstem package dependency lemmatize language transcript. converts morphologiocal derivatives root forms. default lemmatize=T. Sometimes want retain language output native form. case, change argument clean_dyads lemmatize=F. clean_dyads() outputs word count metrics pre/post cleaning dyad interlocutor. can useful interested whether one person just doesn’t produce many words produces great deal empty utterances.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/articles/ConversationAlign Step2 Prep.html","id":"dimension-selection","dir":"Articles","previous_headings":"Cleaning, Formatting, Aligning Norms to Your Data","what":"Dimension Selection","title":"ConversationAlign Step2 Prep","text":"magic happens. prep_dyads() yoke published norms >40 possible dimensions every content word transcript (3 time). join executed merging vectorized conversation transcript huge internal lexical database norms spanning 100k English words. prep_dyads() prompt select anywhere 1 3 target dimensions time. Enter number corresponding dimension interest separated spaces hit enter (e.g., 10 14 19) ConversationAlign append published norm available (e.g., concreteness, word length) every running word transcript. quantitative values used subsequent summarize_dyads() step compute alignment.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/articles/ConversationAlign Step2 Prep.html","id":"prep_dyads","dir":"Articles","previous_headings":"","what":"prep_dyads()","title":"ConversationAlign Step2 Prep","text":"-Cleans, formats, vectorizes conversation transwcripts one-word-per-row format -Yokes psycholinguistic norms three dimensions time (<40 possible dimensions) content word. -Retains metadata Arguments prep_dyads:  1) dat_read= name dataframe created read_dyads()  2) omit_stops= T/F (default=T) option remove stopwords 3) lemmatize= lemmatize strings converting entry dictionary form, default lemmatize=TRUE  4) which_stoplist= quoted argument specifying stopword list, options include none, MIT_stops, SMART, CA_OriginalStops, Temple_stops25. Default Temple_stops25","code":"#Example of running the function NurseryRhymes_Prepped <- prep_dyads(dat_read=NurseryRhymes, lemmatize=TRUE, omit_stops=T, which_stoplist=\"Temple_stops25\")"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/articles/ConversationAlign Step2 Prep.html","id":"example-of-a-prepped-dataset","dir":"Articles","previous_headings":"prep_dyads()","what":"Example of a prepped dataset","title":"ConversationAlign Step2 Prep","text":"embedded external data package ‘anger’ values yoked word.","code":"knitr::kable(head(NurseryRhymes_Prepped, 20), format = \"simple\", digits=2)"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/articles/ConversationAlign_Introduction.html","id":"caveats-for-using-conversationalign","dir":"Articles","previous_headings":"","what":"Caveats for Using ConversationAlign","title":"ConversationAlign_Introduction","text":"Language analyses often proliferate complexity. Spend extra time keep careful records logical organization system (e.g., smart filenaming, variable keys, formalized processing pipeline). ConversationAlign works dyadic language transcripts (.e., 2-person dialogues). ConversationAlign parse turns automatically. software aggregate words produced one speaker across sentences rows switch occurs ‘speaker’ column. ConversationAlign strip punctuation special characters automatically. ConversationAlign split/vectorize text one-word-per-row format, retaining variable labels. ConversationAlign retain meta-data throughout text processing (e.g., timestamps, grouping variables). ConversationAlign pretty good detecting repairing unconventional font encoding systems, catch everything, find sorts hidden junk copy/paste interview transcripts random websites YouTube. Inspect transcripts make sure think launching complex computational analysis.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/articles/ConversationAlign_Introduction.html","id":"prepare-your-transcripts-outside-of-the-package","dir":"Articles","previous_headings":"","what":"Prepare your Transcripts Outside of the Package","title":"ConversationAlign_Introduction","text":"Save conversation transcript separate file (*.txt, *.csv, Otter *.ai). deliberate filenaming convention. transcript’s filename become unique document identifier (Event_ID) importing ConversationAlign. Store transcripts want analyze folder (e.g., ’/my_transcripts). transcript folder analysis scripts ideally exist within directory. raw comversation transcript MUST nominally contain least two columns, talker/interlocutor text. Name talker/interlocutor column ‘Interlocutor’, ‘Speaker’, ‘Participant’ (case sensitive). Name text column ‘Text’, ‘Utterance’, ‘Turn’ (case sensitive).","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/articles/ConversationAlign_Introduction.html","id":"installation","dir":"Articles","previous_headings":"","what":"Installation","title":"ConversationAlign_Introduction","text":"Install load development version ConversationAlign GitHub using devtools package.","code":"# Load SemanticDistance library(ConversationAlign)"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/articles/ConversationAlign_Introduction.html","id":"calibaration-transcripts-included-in-conversationalign","dir":"Articles","previous_headings":"Installation","what":"Calibaration Transcripts Included in ConversationAlign","title":"ConversationAlign_Introduction","text":"ConversationAligncontains two sample conversation transcripts pre-load call package. : MaronGross_2013: Interview transcript Marc Maron Terry Gross NPR (2013). NurseryRhymes: Three nursery rhymes looping phrases formatted conversations, cleaned, aligned illustrate formatting pipeline reshaopes conversation transcripts.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/articles/ConversationAlign_Introduction.html","id":"nurseryrhymes","dir":"Articles","previous_headings":"Installation > Calibaration Transcripts Included in ConversationAlign","what":"NurseryRhymes","title":"ConversationAlign_Introduction","text":"","code":"knitr::kable(head(NurseryRhymes, 20), format = \"simple\") str(NurseryRhymes) #> 'data.frame':    228 obs. of  3 variables: #>  $ Event_ID      : chr  \"ItsySpider\" \"ItsySpider\" \"ItsySpider\" \"ItsySpider\" ... #>  $ Participant_ID: chr  \"Yin\" \"Maya\" \"Yin\" \"Maya\" ... #>  $ Text_Raw      : chr  \"The itsy-bitsy spider climbed up the water spout\" \"Down came the rain and washed the spider out\" \"Out came the sun, and dried up all the rain\" \"And the itsy-bitsy spider climbed up the spout again\" ..."},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/articles/ConversationAlign_Introduction.html","id":"maron-gross-interview","dir":"Articles","previous_headings":"Installation > Calibaration Transcripts Included in ConversationAlign","what":"Maron-Gross Interview","title":"ConversationAlign_Introduction","text":"’s one 2013 NPR interview (USA) Marc Maron Terry Gross, titled Marc Maron: Life Fueled ‘Panic Dread’.","code":"knitr::kable(head(MaronGross_2013, 20), format = \"simple\") str(MaronGross_2013) #> 'data.frame':    546 obs. of  2 variables: #>  $ speaker: chr  \"MARON\" \"MARON\" \"MARON\" \"GROSS\" ... #>  $ text   : chr  \" I'm a little nervous but I've prepared I've written things on a piece of paper\" \" I don't know how you prepare I could ask you that - maybe I will But this is how I prepare - I panic\" \" For a while\" \" Yeah\" ..."},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/articles/ConversationAlign_Introduction.html","id":"caveat-emptor","dir":"Articles","previous_headings":"","what":"Caveat emptor","title":"ConversationAlign_Introduction","text":"analysis language comes assumptions potential bias. example, instances researcher might care morphemes grammatical elements ‘’, ‘’, ‘’, etc.. default ConversationAlign omit stopwords average across open class words (e.g., nouns, verbs) turn interlocutor. specific cases can go wrong. things consider: Stopwords : ConversationAlign omits stopwords default applying customized stopword list, Temple_Stopwords25. CLICK inspect list. stopword list includes greetings, idioms, filler words, numerals, pronouns. Lemmatization : package lemmatize language transcripts default. Lemmatization transforms inflected forms (e.g., standing, stands) root dictionary entry (e.g., stand). helps yoking offline values (e.g., happiness, concreteness) word also entails NLP folks refer ‘term aggregation’. However, sometimes might want lemmatize. can easily change option using argument, “lemmatize=FALSE,” clean_dyads function . Sample Size Issue 1: Exchange Count: program derives correlations AUC dyad metrics alignment. brief conversations (<30 turns), likelihood unstable unreliable estimates high. Sample Size Issue 2 : matching lookup database: ConversationAlign works yoking values lookup database word language transcript. variables lots values characterizing many English words. variables (e.g., age acquisition) cover 30k words. word transcript ‘match’ lookup datase, ConversationAlign return NA go average words interlocutor turn. can dangerous many missing values. Beware! Compositionality : ConversationAlign caveman complexity. matches value word word island. Phenomena like polysemy (e.g., bank) modulation one word intensifier (e.g., terrible) handled. problem many affective measures lexical variables like word length.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/articles/ConversationAlign_Introduction.html","id":"background-and-supporting-materials","dir":"Articles","previous_headings":"","what":"Background and Supporting Materials","title":"ConversationAlign_Introduction","text":"Preprint  PsyArXiv preprint describing method(s) greater detail referenced : Sacks, B., Ulichney, V., Duncan, ., Helion, C., Weinstein, S., Giovannetti, T., … Reilly, J. (2025, March 12). ConversationAlign: Open-Source Software Analyzing Patterns Lexical Use Alignment Conversation Transcripts. Click read preprint. recently invited revision Behavior Rsearch Methods. update /eventually accepted ! Methods creating internal lookup database  ConversationAlign contains large, internal lexical lookup_database. Click see created merging offline psycholinguistic databases one. Variable Key ConversationAlign  ConversationAlign currently allows users compute alignment dynamics across >40 different lexical, affective, semantic dimensions.Click link variable key.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/articles/ConversationAlign_Introduction.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"ConversationAlign_Introduction","text":"Lewis, David D., et al. (2004) “Rcv1: new benchmark collection text categorization research.” Journal machine learning research 5: 361-397.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/articles/ConversationAlign_Step1_Read.html","id":"reading-data-into-r-for-conversationalign","dir":"Articles","previous_headings":"","what":"Reading data into R for ConversationAlign","title":"ConversationAlign_Step1_Read","text":"Half battle R getting data imported formatted. especially true string data working text. ConversationAlign uses series sequential functions import, clean, format raw data. MUST run functions. append important variable names automatically reshape data.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/articles/ConversationAlign_Step1_Read.html","id":"prepping-your-data-for-import","dir":"Articles","previous_headings":"","what":"Prepping your data for import","title":"ConversationAlign_Step1_Read","text":"ConversationAlign works dyadic (.e., two person) conversation transcripts. transcript must nominally contain two colummns, one column delineate interlocutor (person produced text), another column contain text . ConversationAlign contains import function called read_dyads() scan target folder text samples. read_dyads() import transcripts R concatenate single dataframe. read_dyads() append transcript’s filename unique identifier conversation. SUPER important remember analyzing data. Store individual conversation transcripts (.csv, .txt, .ai) wish concatenate corpus folder. ConversationAlign search folder called my_transcripts directory script. However, feel free name folder anything like. can specify custom path argument read_dyads() transcript must nominally contain two columns data (Participant Text). columns (e.g., meta-data) retained.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/articles/ConversationAlign_Step1_Read.html","id":"read_dyads","dir":"Articles","previous_headings":"Prepping your data for import","what":"read_dyads()","title":"ConversationAlign_Step1_Read","text":"exampples read_dyads() action. one argument read_dyads(), my_path. supplying quoted directory path folder transcripts live. Remember treat folder staging area! finished set transcripts don’t want read ConversationAlign move folder, specify new folder. Language data tends proliferate quickly, easy forget . CAREFUL secretary, record steps. Arguments read_dyads include:  1. my_path: default ‘my_transcripts’, change path folder name","code":"#will search for folder 'my_transcripts' in your current directory MyConvos <- read_dyads()  #will scan custom folder called 'MyStuff' in your current directory, concatenating all files in that folder into a single dataframe MyConvos2 <- read_dyads(my_path='/MyStuff')"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/articles/ConversationAlign_Step1_Read.html","id":"read_1file","dir":"Articles","previous_headings":"Prepping your data for import","what":"read_1file()","title":"ConversationAlign_Step1_Read","text":"Read single transcript already R environment. use read_1file() prep Marc Maron Terry Gross transcript. Look column headers changed object name (MaronGross_2013) now Event_ID (document identifier), Arguments read_1file include:  1. my_dat: object already R environment containing text speaker information.","code":"MaryLittleLamb <- read_1file(MaronGross_2013) #print first ten rows of header knitr::kable(head(MaronGross_2013, 15), format = \"pipe\")"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/articles/ConversationAlign_Step2_Prep.html","id":"cleaning-formatting-aligning-norms-to-your-data","dir":"Articles","previous_headings":"","what":"Cleaning, Formatting, Aligning Norms to Your Data","title":"ConversationAlign_Step2_Prep","text":"Lots wild operations happen next step transform unstructured text numeric time series objects aggregated conversation interlocutor. important handle prep_dyads() processes lemmatization stopword removal mean. prep_dyads() uses numerous regex clean format data just read R previous step. ConversationAlign applies ordered sequence cleaning steps road toward vectorizing original text one-word-per row format. steps include: converting text lowercase, expanding contractions, omitting non-alphabetic characters (e.g., numbers, punctuation, line breaks). addition text cleaning, users guide options stopword removal lemmatization. formatting prep_dyads() prompt select three variables computing alignment . works joining values large internal lookup database word language transcript. prep_dyads() customizable via following arguments.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/articles/ConversationAlign_Step2_Prep.html","id":"stopword-removal","dir":"Articles","previous_headings":"Cleaning, Formatting, Aligning Norms to Your Data","what":"Stopword removal","title":"ConversationAlign_Step2_Prep","text":"two important arguments regarding stopword removal. omit_stops specifies whether remove stopwords. which_stopwords specifies stopword list like apply default Temple_stops25. full list choices : none, SMART_stops, CA_orig_stops. MIT_stops, Temple_stops25. Stopword removal important, yet also controversial step text cleaning.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/articles/ConversationAlign_Step2_Prep.html","id":"lemmatization","dir":"Articles","previous_headings":"Cleaning, Formatting, Aligning Norms to Your Data","what":"Lemmatization","title":"ConversationAlign_Step2_Prep","text":"ConversationAlign calls textstem package dependency lemmatize language transcript. converts morphologiocal derivatives root forms. default lemmatize=T. Sometimes want retain language output native form. case, change argument clean_dyads lemmatize=F. clean_dyads() outputs word count metrics pre/post cleaning dyad interlocutor. can useful interested whether one person just doesn’t produce many words produces great deal empty utterances.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/articles/ConversationAlign_Step2_Prep.html","id":"dimension-selection","dir":"Articles","previous_headings":"Cleaning, Formatting, Aligning Norms to Your Data","what":"Dimension Selection","title":"ConversationAlign_Step2_Prep","text":"magic happens. prep_dyads() yoke published norms >40 possible dimensions every content word transcript (3 time). join executed merging vectorized conversation transcript huge internal lexical database norms spanning 100k English words. prep_dyads() prompt select anywhere 1 3 target dimensions time. Enter number corresponding dimension interest separated spaces hit enter (e.g., 10 14 19) ConversationAlign append published norm available (e.g., concreteness, word length) every running word transcript. quantitative values used subsequent summarize_dyads() step compute alignment.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/articles/ConversationAlign_Step2_Prep.html","id":"prep_dyads","dir":"Articles","previous_headings":"","what":"prep_dyads()","title":"ConversationAlign_Step2_Prep","text":"-Cleans, formats, vectorizes conversation transwcripts one-word-per-row format -Yokes psycholinguistic norms three dimensions time (<40 possible dimensions) content word. -Retains metadata Arguments prep_dyads:  1) dat_read= name dataframe created read_dyads()  2) omit_stops= T/F (default=T) option remove stopwords 3) lemmatize= lemmatize strings converting entry dictionary form, default lemmatize=TRUE  4) which_stoplist= quoted argument specifying stopword list, options include none, MIT_stops, SMART, CA_OriginalStops, Temple_stops25. Default Temple_stops25  5) remove_backchannel= logical, turns comprised entirely stopwords removed preserved NAs. NAs filled future steps. Defaults FALSE.","code":"#Example of running the function NurseryRhymes_Prepped <- prep_dyads(dat_read=NurseryRhymes, lemmatize=TRUE, omit_stops=T, which_stoplist=\"Temple_stops25\")"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/articles/ConversationAlign_Step2_Prep.html","id":"example-of-a-prepped-dataset","dir":"Articles","previous_headings":"prep_dyads()","what":"Example of a prepped dataset","title":"ConversationAlign_Step2_Prep","text":"embedded external data package ‘anger’ values yoked word.","code":"knitr::kable(head(NurseryRhymes_Prepped, 20), format = \"simple\", digits=2)"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/articles/ConversationAlign_Step3_Summarize.html","id":"generating-sham-conversations","dir":"Articles","previous_headings":"","what":"Generating sham conversations","title":"ConversationAlign_Step3_Summarize","text":"research questions benefit use conversations control temporal effects. function generate_shams() accepts output prep_dyads() returns data frame structure interlocutor’s time series randomly shuffled. Since output format prep_dyads() output, can easily supplied summarize_dyads() compared real conversations. Arguments generate_shams() include:  1) df_prep= dataframe created prep_dyads()function  2) seed= numeric, number supply seed. allows reproducible results.","code":"MaryShams <- generate_shams(df_prep = NurseryRhymes_Prepped, seed = 10) MarySumDatShams <- summarize_dyads(df_prep = MaryShams, custom_lags=NULL, sumdat_only = TRUE, corr_type='Pearson')  knitr::kable(head(MarySumDatShams, 15), format = \"simple\", digits = 3)"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Jamie Reilly. Author, maintainer. Virginia Ulichney. Author. Ben Sacks. Author. Sarah Weinstein. Contributor. Chelsea Helion. Contributor. Gus Cooney. Contributor.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Reilly J, Ulichney V, Sacks B (2025). ConversationAlign: Process Text Compute Linguistic Alignment Conversation Transcripts. R package version 0.3.2, https://github.com/Reilly-ConceptsCognitionLab/ConversationAlign.","code":"@Manual{,   title = {ConversationAlign: Process Text and Compute Linguistic Alignment in Conversation Transcripts},   author = {Jamie Reilly and Virginia Ulichney and Ben Sacks},   year = {2025},   note = {R package version 0.3.2},   url = {https://github.com/Reilly-ConceptsCognitionLab/ConversationAlign}, }"},{"path":[]},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"Process Text and Compute Linguistic Alignment in Conversation Transcripts","text":"ConversationAlign analyzes alignment computes main effects across 40 unique dimensions interlocutors (conversation partners) engaged two-person conversations. ConversationAlign transforms raw language data simultaneous time series objects across >40 possible dimensions via embedded lookup database. number issues consider steps take prepare data.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"license","dir":"","previous_headings":"","what":"License","title":"Process Text and Compute Linguistic Alignment in Conversation Transcripts","text":"ConversationAlign licensed GNU LGPL v3.0.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"installation-and-technical-considerations","dir":"","previous_headings":"","what":"Installation and Technical Considerations","title":"Process Text and Compute Linguistic Alignment in Conversation Transcripts","text":"One main features ConversationAlign algorithm involves yoking norms many different lexical, affective, semantic dimensions content word conversation transcripts interest. accomplish joining data several large lookup databases. databases large embed within ConversationAlign. load ConversationAlign, databases automatically download load external companionn repository ConversationAlign_Data. ConversationAlign needs data, need decent internet connection load package. might take second two complete download Github acting . Install development version ConversationAlign GitHub using devtools package.","code":"# Check if devtools is installed, if not install it if (!require(\"devtools\", quietly = TRUE)) {   install.packages(\"devtools\") }  # Load devtools library(devtools)  # Check if ConversationAlign is installed, if not install from GitHub if (!require(\"ConversationAlign\", quietly = TRUE)) {   devtools::install_github(\"Reilly-ConceptsCognitionLab/ConversationAlign\") }  # Load SemanticDistance library(ConversationAlign)"},{"path":[]},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"read_dyads","dir":"","previous_headings":"","what":"read_dyads()","title":"Process Text and Compute Linguistic Alignment in Conversation Transcripts","text":"Reads transcripts local drive directory choice. Store individual conversation transcripts (.csv, .txt, .ai) wish concatenate corpus folder. ConversationAlign search folder called my_transcripts directory script. However, feel free name folder anything like. can specify custom path argument read_dyads() transcript must nominally contain two columns data (Participant Text). columns (e.g., meta-data) retained.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"arguments-to-read_dyads--","dir":"","previous_headings":"read_dyads()","what":"Arguments to read_dyads:","title":"Process Text and Compute Linguistic Alignment in Conversation Transcripts","text":"my_path default ‘my_transcripts’, change path folder name","code":"#will search for folder 'my_transcripts' in your current directory MyConvos <- read_dyads()  #will scan custom folder called 'MyStuff' in your current directory, concatenating all files in that folder into a single dataframe MyConvos2 <- read_dyads(my_path='/MyStuff')"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"read_1file","dir":"","previous_headings":"","what":"read_1file()","title":"Process Text and Compute Linguistic Alignment in Conversation Transcripts","text":"Read single transcript already R environment. use read_1file() prep Marc Maron Terry Gross transcript. Look column headers changed object name (MaronGross_2013) now Event_ID (document identifier),","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"arguments-to-read_1file--","dir":"","previous_headings":"read_1file()","what":"Arguments to read_1file:","title":"Process Text and Compute Linguistic Alignment in Conversation Transcripts","text":"my_dat object already R environment containing text speaker information.","code":"MaryLittleLamb <- read_1file(MaronGross_2013) #print first ten rows of header knitr::kable(head(MaronGross_2013, 10), format = \"pipe\")"},{"path":[]},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"prep_dyads","dir":"","previous_headings":"","what":"prep_dyads()","title":"Process Text and Compute Linguistic Alignment in Conversation Transcripts","text":"-Cleans, formats, vectorizes conversation transwcripts one-word-per-row format -Yokes psycholinguistic norms three dimensions time (<40 possible dimensions) content word. -Retains metadata","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"arguments-to-prep_dyads--","dir":"","previous_headings":"prep_dyads()","what":"Arguments to prep_dyads():","title":"Process Text and Compute Linguistic Alignment in Conversation Transcripts","text":"dat_read name dataframe created read_dyads() omit_stops T/F (default=T) option remove stopwords lemmatize T/F (default=T) lemmatize strings converting entry dictionary form which_stoplist quoted argument specifying stopword list apply, options include none, MIT_stops, SMART_stops, CA_OriginalStops, Temple_stops25. Default Temple_stops25. Example prepped dataset embedded external data package ‘anger’ values yoked word.","code":"NurseryRhymes_Prepped <- prep_dyads(dat_read=NurseryRhymes, lemmatize=TRUE, omit_stops=T, which_stoplist=\"Temple_stops25\") knitr::kable(head(NurseryRhymes_Prepped, 10), format = \"simple\", digits=2)"},{"path":[]},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"summarize_dyads","dir":"","previous_headings":"","what":"summarize_dyads()","title":"Process Text and Compute Linguistic Alignment in Conversation Transcripts","text":"computational stage package generates dataframe boiled two rows per converation summary data appended level Participant_ID. returns difference time series AUC (dAUC) every variable interest specified correlation lags -2,,0, 2. decide whether want Pearson Spearman lagged correlation.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"arguments-to-summarize_dyads--","dir":"","previous_headings":"summarize_dyads()","what":"Arguments to summarize_dyads():","title":"Process Text and Compute Linguistic Alignment in Conversation Transcripts","text":"df_prep dataframe created prep_dyads() function custom_lags user specifies custom set turn-lags. Default NULL ConversationAlign producing correlations lead 2 turns, immediate response, lag 2 turns dimension interest. sumdat_only default TRUE, produces grouped summary dataframe averages conversation participant alignment dimension, FALSE retrains original rows, filling empty rows summary statistics conversation (e.g., AUC) corr_type specifies correlation madel (parametric default = ‘Pearson’); option ‘Spearman’ computing turn--turn correlations across interlocutors dimension interest.","code":"MarySumDat <- summarize_dyads(df_prep = NurseryRhymes_Prepped, custom_lags=NULL, sumdat_only = TRUE, corr_type='Pearson')  colnames(MarySumDat) #>  [1] \"Event_ID\"           \"Participant_ID\"     \"Dimension\"          #>  [4] \"Dimension_Mean\"     \"AUC_raw\"            \"AUC_scaled100\"      #>  [7] \"Talked_First\"       \"TurnCorr_Lead2\"     \"TurnCorr_Immediate\" #> [10] \"TurnCorr_Lag2\" knitr::kable(head(MarySumDat, 10), format = \"simple\", digits = 3)"},{"path":[]},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"corpus_analytics","dir":"","previous_headings":"","what":"corpus_analytics()","title":"Process Text and Compute Linguistic Alignment in Conversation Transcripts","text":"often critical produce descriptives/summary statistics characterize language sample. typically laborious process. corpus_analytics , generating near publication ready table analytics can easily export specific journal format choice using number packages flextable tinytable.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"arguments-to-corpus_analytics","dir":"","previous_headings":"corpus_analytics()","what":"Arguments to corpus_analytics():","title":"Process Text and Compute Linguistic Alignment in Conversation Transcripts","text":"dat_prep dataframe created prep_dyads()function","code":"NurseryRhymes_Analytics <-  corpus_analytics(dat_prep=NurseryRhymes_Prepped) knitr::kable(head(NurseryRhymes_Analytics, 10), format = \"simple\", digits = 2)"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/index.html","id":"news-and-getting-help","dir":"","previous_headings":"","what":"News and Getting Help","title":"Process Text and Compute Linguistic Alignment in Conversation Transcripts","text":"Bugs/Features:Open Issue Questions:Join Discussion Urgent:Email jamie.reilly@temple.edu","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU Lesser General Public License","title":"GNU Lesser General Public License","text":"Version 3, 29 June 2007Copyright © 2007 Free Software Foundation, Inc. <http://fsf.org/> Everyone permitted copy distribute verbatim copies license document, changing allowed. version GNU Lesser General Public License incorporates terms conditions version 3 GNU General Public License, supplemented additional permissions listed .","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/LICENSE.html","id":"id_0-additional-definitions","dir":"","previous_headings":"","what":"0. Additional Definitions","title":"GNU Lesser General Public License","text":"used herein, “License” refers version 3 GNU Lesser General Public License, “GNU GPL” refers version 3 GNU General Public License. “Library” refers covered work governed License, Application Combined Work defined . “Application” work makes use interface provided Library, otherwise based Library. Defining subclass class defined Library deemed mode using interface provided Library. “Combined Work” work produced combining linking Application Library. particular version Library Combined Work made also called “Linked Version”. “Minimal Corresponding Source” Combined Work means Corresponding Source Combined Work, excluding source code portions Combined Work , considered isolation, based Application, Linked Version. “Corresponding Application Code” Combined Work means object code /source code Application, including data utility programs needed reproducing Combined Work Application, excluding System Libraries Combined Work.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/LICENSE.html","id":"id_1-exception-to-section-3-of-the-gnu-gpl","dir":"","previous_headings":"","what":"1. Exception to Section 3 of the GNU GPL","title":"GNU Lesser General Public License","text":"may convey covered work sections 3 4 License without bound section 3 GNU GPL.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/LICENSE.html","id":"id_2-conveying-modified-versions","dir":"","previous_headings":"","what":"2. Conveying Modified Versions","title":"GNU Lesser General Public License","text":"modify copy Library, , modifications, facility refers function data supplied Application uses facility (argument passed facility invoked), may convey copy modified version: ) License, provided make good faith effort ensure , event Application supply function data, facility still operates, performs whatever part purpose remains meaningful, b) GNU GPL, none additional permissions License applicable copy.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/LICENSE.html","id":"id_3-object-code-incorporating-material-from-library-header-files","dir":"","previous_headings":"","what":"3. Object Code Incorporating Material from Library Header Files","title":"GNU Lesser General Public License","text":"object code form Application may incorporate material header file part Library. may convey object code terms choice, provided , incorporated material limited numerical parameters, data structure layouts accessors, small macros, inline functions templates (ten fewer lines length), following: ) Give prominent notice copy object code Library used Library use covered License. b) Accompany object code copy GNU GPL license document.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/LICENSE.html","id":"id_4-combined-works","dir":"","previous_headings":"","what":"4. Combined Works","title":"GNU Lesser General Public License","text":"may convey Combined Work terms choice , taken together, effectively restrict modification portions Library contained Combined Work reverse engineering debugging modifications, also following: ) Give prominent notice copy Combined Work Library used Library use covered License. b) Accompany Combined Work copy GNU GPL license document. c) Combined Work displays copyright notices execution, include copyright notice Library among notices, well reference directing user copies GNU GPL license document. d) one following: 0) Convey Minimal Corresponding Source terms License, Corresponding Application Code form suitable , terms permit, user recombine relink Application modified version Linked Version produce modified Combined Work, manner specified section 6 GNU GPL conveying Corresponding Source. 1) Use suitable shared library mechanism linking Library. suitable mechanism one () uses run time copy Library already present user’s computer system, (b) operate properly modified version Library interface-compatible Linked Version. e) Provide Installation Information, otherwise required provide information section 6 GNU GPL, extent information necessary install execute modified version Combined Work produced recombining relinking Application modified version Linked Version. (use option 4d0, Installation Information must accompany Minimal Corresponding Source Corresponding Application Code. use option 4d1, must provide Installation Information manner specified section 6 GNU GPL conveying Corresponding Source.)","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/LICENSE.html","id":"id_5-combined-libraries","dir":"","previous_headings":"","what":"5. Combined Libraries","title":"GNU Lesser General Public License","text":"may place library facilities work based Library side side single library together library facilities Applications covered License, convey combined library terms choice, following: ) Accompany combined library copy work based Library, uncombined library facilities, conveyed terms License. b) Give prominent notice combined library part work based Library, explaining find accompanying uncombined form work.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/LICENSE.html","id":"id_6-revised-versions-of-the-gnu-lesser-general-public-license","dir":"","previous_headings":"","what":"6. Revised Versions of the GNU Lesser General Public License","title":"GNU Lesser General Public License","text":"Free Software Foundation may publish revised /new versions GNU Lesser General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Library received specifies certain numbered version GNU Lesser General Public License “later version” applies , option following terms conditions either published version later version published Free Software Foundation. Library received specify version number GNU Lesser General Public License, may choose version GNU Lesser General Public License ever published Free Software Foundation. Library received specifies proxy can decide whether future versions GNU Lesser General Public License shall apply, proxy’s public statement acceptance version permanent authorization choose version Library.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/ConversationAlign-package.html","id":null,"dir":"Reference","previous_headings":"","what":"ConversationAlign: Process Text and Compute Linguistic Alignment in Conversation Transcripts — ConversationAlign-package","title":"ConversationAlign: Process Text and Compute Linguistic Alignment in Conversation Transcripts — ConversationAlign-package","text":"Imports conversation transcripts R, concatenates single dataframe appending event identifiers, cleans formats text, yokes user-specified psycholinguistic database values word. 'ConversationAlign' computes alignment indices two interlocutors across transcript >40 possible semantic, lexical, affective dimensions. addition alignment, 'ConversationAlign' also produces table analytics (e.g., token count, type-token-ratio) summary table describing particular text corpus.","code":""},{"path":[]},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/ConversationAlign-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"ConversationAlign: Process Text and Compute Linguistic Alignment in Conversation Transcripts — ConversationAlign-package","text":"Maintainer: Jamie Reilly jamie_reilly@temple.edu (ORCID) Authors: Virginia Ulichney Ben Sacks contributors: Sarah Weinstein [contributor] Chelsea Helion [contributor] Gus Cooney [contributor]","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/corpus_analytics.html","id":null,"dir":"Reference","previous_headings":"","what":"corpus_analytics — corpus_analytics","title":"corpus_analytics — corpus_analytics","text":"Produces table corpus analytics including numbers complete observations step, word counts, lexical diversity (e.g., TTR), stopword ratios, etc. Granularity summary statistics guided user (e.g., conversation, conversation speaker, collapsed )","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/corpus_analytics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"corpus_analytics — corpus_analytics","text":"","code":"corpus_analytics(dat_prep)"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/corpus_analytics.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"corpus_analytics — corpus_analytics","text":"dat_prep takes dataframe produced df_prep() function","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/corpus_analytics.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"corpus_analytics — corpus_analytics","text":"dataframe summary statistics (mean, SD, range) numerous corpus analytics (e.g., token count, type-token-ratio, word-count-per-turn) target conversation corpus. Summary data structured table format easy export journal method section.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/generate_shams.html","id":null,"dir":"Reference","previous_headings":"","what":"generate_shams — generate_shams","title":"generate_shams — generate_shams","text":"Generates permutation individual dyad. Shuffled dyads may act controls originals.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/generate_shams.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"generate_shams — generate_shams","text":"","code":"generate_shams(df_prep, seed = NULL)"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/generate_shams.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"generate_shams — generate_shams","text":"df_prep Output dataframe prep_dyads(). seed (Optional) seed reproducibility random sampling","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/generate_shams.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"generate_shams — generate_shams","text":"dataframe similar prepped dyads, participant's time series randomly shuffled.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/load_github_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Load all .rda files from a GitHub data folder into the package environment — load_github_data","title":"Load all .rda files from a GitHub data folder into the package environment — load_github_data","text":"Load .rda files GitHub data folder package environment","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/load_github_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load all .rda files from a GitHub data folder into the package environment — load_github_data","text":"","code":"load_github_data(   repo = \"Reilly-ConceptsCognitionLab/ConversationAlign_Data\",   branch = \"main\",   data_folder = \"data\",   envir = parent.frame() )"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/load_github_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load all .rda files from a GitHub data folder into the package environment — load_github_data","text":"repo GitHub repository (e.g., \"username/repo\") branch Branch name (default: \"main\") data_folder Remote folder containing .rda files (default: \"data/\") envir Environment load (default: package namespace)","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/load_github_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Load all .rda files from a GitHub data folder into the package environment — load_github_data","text":"nothing, loads data (rda files) github repository needed package functions","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/MaronGross_2013.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample Dyadic Interview Transcript: Marc Maron and Terry Gross Radio Interview 2013 — MaronGross_2013","title":"Sample Dyadic Interview Transcript: Marc Maron and Terry Gross Radio Interview 2013 — MaronGross_2013","text":"Text talker information delineated, raw transcript, multiple lines per talker","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/MaronGross_2013.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample Dyadic Interview Transcript: Marc Maron and Terry Gross Radio Interview 2013 — MaronGross_2013","text":"","code":"MaronGross_2013"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/MaronGross_2013.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Sample Dyadic Interview Transcript: Marc Maron and Terry Gross Radio Interview 2013 — MaronGross_2013","text":"## \"MaronGross_2013\" data.frame 546 obs, 2 vars: text text interview speaker speaker identity","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/NurseryRhymes.html","id":null,"dir":"Reference","previous_headings":"","what":"Text and talker information delineated, 3 separate nursery rhymes, good for computing analytics and word counts — NurseryRhymes","title":"Text and talker information delineated, 3 separate nursery rhymes, good for computing analytics and word counts — NurseryRhymes","text":"Text talker information delineated, 3 separate nursery rhymes, good computing analytics word counts","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/NurseryRhymes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Text and talker information delineated, 3 separate nursery rhymes, good for computing analytics and word counts — NurseryRhymes","text":"","code":"NurseryRhymes"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/NurseryRhymes.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Text and talker information delineated, 3 separate nursery rhymes, good for computing analytics and word counts — NurseryRhymes","text":"## \"NurseryRhymes\" data.frame 100 observations, 2 vars: Event_ID factor 3 different simulated conversations Participant_ID fictional speaker names, 2 conversation Text_Raw simulated language production, actually looped phrases nursery rhymes","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/NurseryRhymes_Prepped.html","id":null,"dir":"Reference","previous_headings":"","what":"Text and talker information delineated, 3 separate nursery rhymes, good for computing analytics and word counts — NurseryRhymes_Prepped","title":"Text and talker information delineated, 3 separate nursery rhymes, good for computing analytics and word counts — NurseryRhymes_Prepped","text":"Text talker information delineated, 3 separate nursery rhymes, good computing analytics word counts","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/NurseryRhymes_Prepped.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Text and talker information delineated, 3 separate nursery rhymes, good for computing analytics and word counts — NurseryRhymes_Prepped","text":"","code":"NurseryRhymes_Prepped"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/NurseryRhymes_Prepped.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Text and talker information delineated, 3 separate nursery rhymes, good for computing analytics and word counts — NurseryRhymes_Prepped","text":"## \"NurseryRhymes_Prepped\" data.frame 1507 x 7 observations, 5 vars: Event_ID factor 3 different simulated conversations Participant_ID fictional speaker names, 2 conversation Exchange_Count sequential numbering exchanges conversation, 1 exchange = 2 turns Turn_Count sequential numbering turns conversation Text_Clean content words emo_anger raw value anger salience yoked word","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/prep_dyads.html","id":null,"dir":"Reference","previous_headings":"","what":"prep_dyads — prep_dyads","title":"prep_dyads — prep_dyads","text":"Cleans, vectorizes appends lexical norms content words language corpus. User guides options stopword removal lemmatization. User selects three psycholinguistic dimensions yoke norms content word original conversation transcript.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/prep_dyads.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"prep_dyads — prep_dyads","text":"","code":"prep_dyads(   dat_read,   lemmatize = TRUE,   omit_stops = TRUE,   which_stoplist = \"Temple_stops25\",   remove_backchannel = FALSE,   verbose = TRUE )"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/prep_dyads.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"prep_dyads — prep_dyads","text":"dat_read dataframe produced read_dyads() function lemmatize logical, words lemmatized (switched base morphological form), default TRUE omit_stops option remove stopwords, default TRUE which_stoplist user-specified stopword removal method options including \"none\", \"SMART\", \"MIT_stops\", \"CA_OriginalStops\", \"Temple_Stopwords25\". \"Temple_Stopwords25 default list remove_backchannel logical, turns full stopwords (e.g., \"Uhm yeah\") preserved NAs removed. Removal 'squish' turn together one. NAs preserved later interpolated. verbose display detailed output error messages progress (default TRUE)","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/prep_dyads.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"prep_dyads — prep_dyads","text":"dataframe text cleaned vectorized one word per-row format. Lexical norms metadata appended content word. Cleaned text appears new column called 'Text_Clean'. selected dimensions (e.g., word length) metadata also appended word along speaker identity, turn, Event_ID (conversation identifier).","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/read_1file.html","id":null,"dir":"Reference","previous_headings":"","what":"read_1file — read_1file","title":"read_1file — read_1file","text":"Reads pre-formatted dyadic (2 interlocutor) conversation transcript already imported R environment.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/read_1file.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"read_1file — read_1file","text":"","code":"read_1file(my_dat)"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/read_1file.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"read_1file — read_1file","text":"my_dat one conversation transcript already R environment","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/read_1file.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"read_1file — read_1file","text":"dataframe formatted 'Event_ID', \"Participant_ID\", \"Text_Raw\" fields – ready clean_dyads()","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/read_dyads.html","id":null,"dir":"Reference","previous_headings":"","what":"read_dyads — read_dyads","title":"read_dyads — read_dyads","text":"Reads pre-formatted dyadic (2 interlocutor) conversation transcripts machine. Transcripts must either csv txt format. supplying txt file, transcript must formatted otter.ai txt file export. options using csv files flexible. ConversationAlign minimally requires csv file two columns, denoting interlocutor text. separate conversation transcript saved separate file. ConversationAlign use file names document ID. Within read dyads function, set my_path argument directory path local folder containing transcripts machine (e.g., \"my_transcripts\"). Please see github page examples properly formatted transcripts: https://github.com/Reilly-ConceptsCognitionLab/ConversationAlign","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/read_dyads.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"read_dyads — read_dyads","text":"","code":"read_dyads(my_path = \"my_transcripts\")"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/read_dyads.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"read_dyads — read_dyads","text":"my_path folder conversation transcripts csv txt format","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/read_dyads.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"read_dyads — read_dyads","text":"dataframe individual conversation transcript user's directory concatenated. read_dyads appends unique document identifier conversation transcript appending unique filename factor level 'Event_ID'.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/summarize_dyads.html","id":null,"dir":"Reference","previous_headings":"","what":"summarize_dyads — summarize_dyads","title":"summarize_dyads — summarize_dyads","text":"Calculates appends 3 measures quantifying alignment. Appends averaged value selected dimension turn speaker. Calculates Spearman's rank correlation interlocutor time series appends transcript. Calculates area curve absolute difference time series interlocutor time series. length difference time series can standardized shortest number exchanges present group using internally defined resampling function, called resample = TRUE. Spearman's rank correlation area curve become less reliable dyads 30 exchanges.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/summarize_dyads.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"summarize_dyads — summarize_dyads","text":"","code":"summarize_dyads(   df_prep,   custom_lags = NULL,   sumdat_only = TRUE,   corr_type = \"Pearson\" )"},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/summarize_dyads.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"summarize_dyads — summarize_dyads","text":"df_prep produced align_dyads function custom_lags integer vector, lags added addition -2, 0, 2 sumdat_only default=TRUE, group summarize data, two rows per conversation, one row participant, false fill summary statistics across exchanges corr_type option computing lagged correlations turn--turn covariance (default='Pearson')","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/ConversationAlign/reference/summarize_dyads.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"summarize_dyads — summarize_dyads","text":"either: - grouped dataframe summary data aggregated converation (Event_ID) participant sumdat_only=T. - origoinal dataframe 'filled ' summary data (e.g., AUC, turn--turn correlations) conversation sumdat_only=F.","code":""}]
